{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "404a08f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing huggingface_hub.hf_api: No module named 'filelock'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Odyssey/private/j25lee/miniforge3/envs/glon/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, \"./src\")\n",
    "from glonet import Glonet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fef1bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n",
      "Device name: NVIDIA H100 NVL\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f9f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/Odyssey/public/glonet/TrainedWeights/glonet_p1.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fefb4abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load(model_path, map_location=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50229a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward schema: forward(__torch__.torch.nn.modules.container.___torch_mangle_1012.Sequential self, Tensor input) -> Tensor\n",
      "forward executed\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     59\u001b[39m     loss = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     64\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minput.grad norm:\u001b[39m\u001b[33m'\u001b[39m, x.grad.norm().item())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Odyssey/private/j25lee/miniforge3/envs/glon/lib/python3.12/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Odyssey/private/j25lee/miniforge3/envs/glon/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Odyssey/private/j25lee/miniforge3/envs/glon/lib/python3.12/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# Move model to device, freeze all parameters, and prepare a gradient-tracked input\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "# Freeze parameters so only input can receive gradients\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "model.eval()\n",
    "\n",
    "# Try to inspect forward signature to guide a dummy input (best-effort).\n",
    "schema = None\n",
    "try:\n",
    "    if hasattr(model, 'forward'):\n",
    "        try:\n",
    "            schema = str(model.forward.schema)\n",
    "        except Exception:\n",
    "            schema = None\n",
    "except Exception:\n",
    "    schema = None\n",
    "print('forward schema:', schema)\n",
    "\n",
    "# Fallback dummy input: adjust shape if your model expects different dims\n",
    "# Common shape: (batch, channels, H, W). Replace as needed before running.\n",
    "x = torch.randn(1, 2, 5, 672, 1440, device=device, requires_grad=True)\n",
    "\n",
    "# Run forward; models may return tensor, tuple, or dict depending on implementation\n",
    "try:\n",
    "    out = model(x)\n",
    "    print('forward executed')\n",
    "except Exception as e:\n",
    "    print('forward failed:', e)\n",
    "    out = None\n",
    "\n",
    "# Inspect output and attempt a backward pass to verify gradient flows into input\n",
    "if out is None:\n",
    "    print('No output to backprop')\n",
    "else:\n",
    "    # pick a tensor to reduce to scalar for backward\n",
    "    if torch.is_tensor(out):\n",
    "        loss = out.sum()\n",
    "    elif isinstance(out, (tuple, list)):\n",
    "        out_t = None\n",
    "        for o in out:\n",
    "            if torch.is_tensor(o):\n",
    "                out_t = o\n",
    "                break\n",
    "        if out_t is None:\n",
    "            print('no tensor in output to backprop')\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = out_t.sum()\n",
    "    elif isinstance(out, dict):\n",
    "        # pick the first tensor value in dict\n",
    "        loss = None\n",
    "        for v in out.values():\n",
    "            if torch.is_tensor(v):\n",
    "                loss = v.sum()\n",
    "                break\n",
    "    else:\n",
    "        loss = None\n",
    "\n",
    "    if loss is not None:\n",
    "        loss.backward()\n",
    "        if x.grad is not None:\n",
    "            print('input.grad norm:', x.grad.norm().item())\n",
    "        else:\n",
    "            print('input.grad is None — gradient did not flow into input')\n",
    "    else:\n",
    "        print('Could not construct a scalar loss for backward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c903d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ac9ddc",
   "metadata": {},
   "source": [
    "**Why the error happens** (short)\n",
    "\n",
    "- That RuntimeError occurs because you called backward() on a tensor that does not require gradients and has no grad_fn. In other words the tensor is not connected to any autograd graph.\n",
    "- Common reasons in your setup:\n",
    " - The object you call backward() on is a Python float or a tensor with requires_grad=False (e.g., you summed or converted to .item(), .numpy(), or detached it).\n",
    " - The model's forward executed inside a torch.no_grad() block or used .detach() / .cpu().numpy() somewhere, preventing gradients.\n",
    " - The TorchScript module you loaded is an inference-only graph that returns detached results (or its forward uses no_grad()).\n",
    " - You froze parameters (that’s fine for input grads) but the forward still prevents grad flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c7e2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.requires_grad: True\n",
      "out_t type: <class 'torch.Tensor'>\n",
      "out_t.requires_grad: False\n",
      "out_t.grad_fn: None\n",
      "-> Output does not require grad. Check for torch.no_grad(), .detach(), or conversions to numpy/float inside forward.\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic helper: finds first tensor in output and prints grad info\n",
    "def find_tensor(o):\n",
    "    if torch.is_tensor(o):\n",
    "        return o\n",
    "    if isinstance(o, (list, tuple)):\n",
    "        for v in o:\n",
    "            t = find_tensor(v)\n",
    "            if t is not None:\n",
    "                return t\n",
    "    if isinstance(o, dict):\n",
    "        for v in o.values():\n",
    "            t = find_tensor(v)\n",
    "            if t is not None:\n",
    "                return t\n",
    "    return None\n",
    "\n",
    "out_t = find_tensor(out)\n",
    "print(\"x.requires_grad:\", getattr(x, \"requires_grad\", None))\n",
    "if out_t is None:\n",
    "    print(\"No tensor found in model output (out is None or not tensor-like).\")\n",
    "else:\n",
    "    print(\"out_t type:\", type(out_t))\n",
    "    print(\"out_t.requires_grad:\", out_t.requires_grad)\n",
    "    print(\"out_t.grad_fn:\", out_t.grad_fn)\n",
    "    # If it does not require grad, show likely suspects\n",
    "    if not out_t.requires_grad:\n",
    "        print(\"-> Output does not require grad. Check for torch.no_grad(), .detach(), or conversions to numpy/float inside forward.\")\n",
    "    else:\n",
    "        # safe backward check\n",
    "        loss = out_t.sum()\n",
    "        print(\"loss.requires_grad:\", loss.requires_grad)\n",
    "        loss.backward()\n",
    "        print(\"x.grad is None?:\", x.grad is None)\n",
    "        if x.grad is not None:\n",
    "            print(\"x.grad norm:\", x.grad.norm().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef224ac",
   "metadata": {},
   "source": [
    "***How to interpret results and fixes***\n",
    "\n",
    "- If `out_t.requires_grad` is False:\n",
    "  - Inspect your model forward for torch.no_grad(), .detach(), or explicit .cpu().numpy() / .item() conversions. Remove or alter them so the forward keeps tensors connected to the graph.\n",
    "  - If you loaded a scripted/inference-only TorchScript (from tracing or an exported inference build), load the original model class + state_dict instead (instantiate `Glonet(...)`, load state_dict) so autograd is available.\n",
    "- If the output is a Python float or you see `loss` created from `.item()` / `.numpy()`, don't convert to float before backward; keep it as a tensor.\n",
    "- If `x.requires_grad` is False (shouldn’t be in your code): recreate x with requires_grad=True.\n",
    "- If model intentionally uses `with torch.no_grad()` for some ops, remove that block for the ops that must be differentiable, or implement a separate \"differentiable forward\" for optimization.\n",
    "\n",
    "If you want, I can:\n",
    "\n",
    "- Edit the notebook to replace the fallback dummy input shape with the correct shape automatically (I can try to infer it), and add the diagnostic prints directly into the cell.\n",
    "- Help load the model from source/state_dict instead of using `torch.jit.load` (if you have the class definition and checkpoint).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecb84f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Glonet(dim=(2, 5, 672, 1440))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fbb09aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Glonet(\n",
       "  (space): mspace(\n",
       "    (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "    (enc): Sequential(\n",
       "      (0): Inception(\n",
       "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Inception(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Inception(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Inception(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): Inception(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Inception(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): Inception(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Inception(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x Fblock(\n",
       "        (normlayer1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (filter): AFNO(\n",
       "          (relu): ReLU()\n",
       "          (bias): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (attn): MHSA(\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (normlayer2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (fc3): AdaptiveAvgPool1d(output_size=64)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec): Sequential(\n",
       "      (0): Inception(\n",
       "        (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Inception(\n",
       "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Inception(\n",
       "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Inception(\n",
       "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): Inception(\n",
       "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Inception(\n",
       "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): Inception(\n",
       "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Inception(\n",
       "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (lls): Sequential(\n",
       "          (0): GroupConv2d(\n",
       "            (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "            (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (1): GroupConv2d(\n",
       "            (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=8)\n",
       "            (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): GroupConv2d(\n",
       "            (conv): Conv2d(32, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=8)\n",
       "            (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "            (activate): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dynamics): tmp(\n",
       "    (NN): SS(\n",
       "      (upconv): ConvTranspose2d(5, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (NO): GF_Block(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (projection): Conv2d(5, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (blks): ModuleList(\n",
       "        (0-11): 12 x Fblock(\n",
       "          (normlayer1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (filter): AFNO(\n",
       "            (relu): ReLU()\n",
       "            (bias): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (attn): MHSA(\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (normlayer2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (fc3): AdaptiveAvgPool1d(output_size=768)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (lproj): Sequential(\n",
       "        (transposeconv1): ConvTranspose2d(768, 80, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (act1): Tanh()\n",
       "        (transposeconv2): ConvTranspose2d(80, 20, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (act2): Tanh()\n",
       "        (transposeconv3): ConvTranspose2d(20, 5, kernel_size=(4, 4), stride=(4, 4))\n",
       "      )\n",
       "      (final_dropout): Identity()\n",
       "    )\n",
       "    (up): ConvTranspose2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (down): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv1x1): Conv2d(5, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (maps): Encoder(\n",
       "    (enc): Sequential(\n",
       "      (0): ConvSC(\n",
       "        (conv): BasicConv2d(\n",
       "          (conv): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
       "          (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ConvSC(\n",
       "        (conv): BasicConv2d(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
       "          (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mapsback): Decoder(\n",
       "    (dec): Sequential(\n",
       "      (0): ConvSC(\n",
       "        (conv): BasicConv2d(\n",
       "          (conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
       "          (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ConvSC(\n",
       "        (conv): BasicConv2d(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
       "          (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): Conv2d(64, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "712290e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=Sequential\n",
       "  (0): RecursiveScriptModule(\n",
       "    original_name=Glonet\n",
       "    (jump): RecursiveScriptModule(\n",
       "      original_name=residual\n",
       "      (maps): RecursiveScriptModule(\n",
       "        original_name=Encoder\n",
       "        (enc): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(\n",
       "            original_name=ConvSC\n",
       "            (conv): RecursiveScriptModule(\n",
       "              original_name=BasicConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (act): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "          (1): RecursiveScriptModule(\n",
       "            original_name=ConvSC\n",
       "            (conv): RecursiveScriptModule(\n",
       "              original_name=BasicConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (act): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "          (2): RecursiveScriptModule(\n",
       "            original_name=ConvSC\n",
       "            (conv): RecursiveScriptModule(\n",
       "              original_name=BasicConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (act): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "          (3): RecursiveScriptModule(\n",
       "            original_name=ConvSC\n",
       "            (conv): RecursiveScriptModule(\n",
       "              original_name=BasicConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (act): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mmb): RecursiveScriptModule(\n",
       "        original_name=MMB\n",
       "        (enc): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (5): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (6): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (7): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (dec): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (5): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (6): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (7): RecursiveScriptModule(\n",
       "            original_name=Inception\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (lls): RecursiveScriptModule(\n",
       "              original_name=Sequential\n",
       "              (0): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (1): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (2): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "              (3): RecursiveScriptModule(\n",
       "                original_name=GroupConv2d\n",
       "                (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "                (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "                (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mapsback): RecursiveScriptModule(\n",
       "        original_name=Decoder\n",
       "        (dec): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(\n",
       "            original_name=ConvSC\n",
       "            (conv): RecursiveScriptModule(\n",
       "              original_name=BasicConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=ConvTranspose2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (act): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "          (1): RecursiveScriptModule(\n",
       "            original_name=ConvSC\n",
       "            (conv): RecursiveScriptModule(\n",
       "              original_name=BasicConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (act): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "          (2): RecursiveScriptModule(\n",
       "            original_name=ConvSC\n",
       "            (conv): RecursiveScriptModule(\n",
       "              original_name=BasicConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=ConvTranspose2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (act): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "          (3): RecursiveScriptModule(\n",
       "            original_name=ConvSC\n",
       "            (conv): RecursiveScriptModule(\n",
       "              original_name=BasicConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (act): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (readout): RecursiveScriptModule(original_name=Conv2d)\n",
       "      )\n",
       "    )\n",
       "    (space): RecursiveScriptModule(\n",
       "      original_name=FoTF\n",
       "      (NN): RecursiveScriptModule(\n",
       "        original_name=Local_CNN_Branch\n",
       "        (upconv): RecursiveScriptModule(original_name=ConvTranspose2d)\n",
       "      )\n",
       "      (NO): RecursiveScriptModule(\n",
       "        original_name=GF_Block\n",
       "        (patch_embed): RecursiveScriptModule(\n",
       "          original_name=PatchEmbed\n",
       "          (projection): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (norm): RecursiveScriptModule(original_name=Identity)\n",
       "        )\n",
       "        (pos_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "        (blks): RecursiveScriptModule(\n",
       "          original_name=ModuleList\n",
       "          (0): RecursiveScriptModule(\n",
       "            original_name=FourierNetBlock\n",
       "            (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (filter): RecursiveScriptModule(\n",
       "              original_name=AdativeFourierNeuralOperator\n",
       "              (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "              (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "            )\n",
       "            (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "            (attn): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (multihead_attn): RecursiveScriptModule(\n",
       "                original_name=MultiheadAttention\n",
       "                (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "              )\n",
       "            )\n",
       "            (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (mlp): RecursiveScriptModule(\n",
       "              original_name=Mlp\n",
       "              (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "              (act): RecursiveScriptModule(original_name=GELU)\n",
       "              (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "              (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "              (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (1): RecursiveScriptModule(\n",
       "            original_name=FourierNetBlock\n",
       "            (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (filter): RecursiveScriptModule(\n",
       "              original_name=AdativeFourierNeuralOperator\n",
       "              (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "              (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "            )\n",
       "            (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "            (attn): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (multihead_attn): RecursiveScriptModule(\n",
       "                original_name=MultiheadAttention\n",
       "                (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "              )\n",
       "            )\n",
       "            (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (mlp): RecursiveScriptModule(\n",
       "              original_name=Mlp\n",
       "              (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "              (act): RecursiveScriptModule(original_name=GELU)\n",
       "              (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "              (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "              (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (2): RecursiveScriptModule(\n",
       "            original_name=FourierNetBlock\n",
       "            (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (filter): RecursiveScriptModule(\n",
       "              original_name=AdativeFourierNeuralOperator\n",
       "              (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "              (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "            )\n",
       "            (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "            (attn): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (multihead_attn): RecursiveScriptModule(\n",
       "                original_name=MultiheadAttention\n",
       "                (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "              )\n",
       "            )\n",
       "            (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (mlp): RecursiveScriptModule(\n",
       "              original_name=Mlp\n",
       "              (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "              (act): RecursiveScriptModule(original_name=GELU)\n",
       "              (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "              (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "              (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (3): RecursiveScriptModule(\n",
       "            original_name=FourierNetBlock\n",
       "            (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (filter): RecursiveScriptModule(\n",
       "              original_name=AdativeFourierNeuralOperator\n",
       "              (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "              (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "            )\n",
       "            (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "            (attn): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (multihead_attn): RecursiveScriptModule(\n",
       "                original_name=MultiheadAttention\n",
       "                (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "              )\n",
       "            )\n",
       "            (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (mlp): RecursiveScriptModule(\n",
       "              original_name=Mlp\n",
       "              (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "              (act): RecursiveScriptModule(original_name=GELU)\n",
       "              (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "              (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "              (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (4): RecursiveScriptModule(\n",
       "            original_name=FourierNetBlock\n",
       "            (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (filter): RecursiveScriptModule(\n",
       "              original_name=AdativeFourierNeuralOperator\n",
       "              (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "              (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "            )\n",
       "            (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "            (attn): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (multihead_attn): RecursiveScriptModule(\n",
       "                original_name=MultiheadAttention\n",
       "                (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "              )\n",
       "            )\n",
       "            (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (mlp): RecursiveScriptModule(\n",
       "              original_name=Mlp\n",
       "              (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "              (act): RecursiveScriptModule(original_name=GELU)\n",
       "              (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "              (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "              (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (5): RecursiveScriptModule(\n",
       "            original_name=FourierNetBlock\n",
       "            (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (filter): RecursiveScriptModule(\n",
       "              original_name=AdativeFourierNeuralOperator\n",
       "              (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "              (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "            )\n",
       "            (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "            (attn): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (multihead_attn): RecursiveScriptModule(\n",
       "                original_name=MultiheadAttention\n",
       "                (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "              )\n",
       "            )\n",
       "            (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (mlp): RecursiveScriptModule(\n",
       "              original_name=Mlp\n",
       "              (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "              (act): RecursiveScriptModule(original_name=GELU)\n",
       "              (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "              (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "              (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (6): RecursiveScriptModule(\n",
       "            original_name=FourierNetBlock\n",
       "            (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (filter): RecursiveScriptModule(\n",
       "              original_name=AdativeFourierNeuralOperator\n",
       "              (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "              (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "            )\n",
       "            (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "            (attn): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (multihead_attn): RecursiveScriptModule(\n",
       "                original_name=MultiheadAttention\n",
       "                (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "              )\n",
       "            )\n",
       "            (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (mlp): RecursiveScriptModule(\n",
       "              original_name=Mlp\n",
       "              (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "              (act): RecursiveScriptModule(original_name=GELU)\n",
       "              (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "              (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "              (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (7): RecursiveScriptModule(\n",
       "            original_name=FourierNetBlock\n",
       "            (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (filter): RecursiveScriptModule(\n",
       "              original_name=AdativeFourierNeuralOperator\n",
       "              (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "              (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "            )\n",
       "            (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "            (attn): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (multihead_attn): RecursiveScriptModule(\n",
       "                original_name=MultiheadAttention\n",
       "                (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "              )\n",
       "            )\n",
       "            (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (mlp): RecursiveScriptModule(\n",
       "              original_name=Mlp\n",
       "              (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "              (act): RecursiveScriptModule(original_name=GELU)\n",
       "              (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "              (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "              (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (8): RecursiveScriptModule(\n",
       "            original_name=FourierNetBlock\n",
       "            (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (filter): RecursiveScriptModule(\n",
       "              original_name=AdativeFourierNeuralOperator\n",
       "              (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "              (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "            )\n",
       "            (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "            (attn): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (multihead_attn): RecursiveScriptModule(\n",
       "                original_name=MultiheadAttention\n",
       "                (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "              )\n",
       "            )\n",
       "            (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (mlp): RecursiveScriptModule(\n",
       "              original_name=Mlp\n",
       "              (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "              (act): RecursiveScriptModule(original_name=GELU)\n",
       "              (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "              (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "              (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (9): RecursiveScriptModule(\n",
       "            original_name=FourierNetBlock\n",
       "            (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (filter): RecursiveScriptModule(\n",
       "              original_name=AdativeFourierNeuralOperator\n",
       "              (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "              (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "            )\n",
       "            (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "            (attn): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (multihead_attn): RecursiveScriptModule(\n",
       "                original_name=MultiheadAttention\n",
       "                (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "              )\n",
       "            )\n",
       "            (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (mlp): RecursiveScriptModule(\n",
       "              original_name=Mlp\n",
       "              (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "              (act): RecursiveScriptModule(original_name=GELU)\n",
       "              (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "              (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "              (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (10): RecursiveScriptModule(\n",
       "            original_name=FourierNetBlock\n",
       "            (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (filter): RecursiveScriptModule(\n",
       "              original_name=AdativeFourierNeuralOperator\n",
       "              (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "              (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "            )\n",
       "            (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "            (attn): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (multihead_attn): RecursiveScriptModule(\n",
       "                original_name=MultiheadAttention\n",
       "                (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "              )\n",
       "            )\n",
       "            (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (mlp): RecursiveScriptModule(\n",
       "              original_name=Mlp\n",
       "              (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "              (act): RecursiveScriptModule(original_name=GELU)\n",
       "              (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "              (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "              (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (11): RecursiveScriptModule(\n",
       "            original_name=FourierNetBlock\n",
       "            (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (filter): RecursiveScriptModule(\n",
       "              original_name=AdativeFourierNeuralOperator\n",
       "              (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "              (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "            )\n",
       "            (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "            (attn): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (multihead_attn): RecursiveScriptModule(\n",
       "                original_name=MultiheadAttention\n",
       "                (out_proj): RecursiveScriptModule(original_name=NonDynamicallyQuantizableLinear)\n",
       "              )\n",
       "            )\n",
       "            (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (mlp): RecursiveScriptModule(\n",
       "              original_name=Mlp\n",
       "              (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "              (act): RecursiveScriptModule(original_name=GELU)\n",
       "              (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "              (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "              (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "        (lproj): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (transposeconv1): RecursiveScriptModule(original_name=ConvTranspose2d)\n",
       "          (act1): RecursiveScriptModule(original_name=Tanh)\n",
       "          (transposeconv2): RecursiveScriptModule(original_name=ConvTranspose2d)\n",
       "          (act2): RecursiveScriptModule(original_name=Tanh)\n",
       "          (transposeconv3): RecursiveScriptModule(original_name=ConvTranspose2d)\n",
       "        )\n",
       "        (final_dropout): RecursiveScriptModule(original_name=Identity)\n",
       "      )\n",
       "      (up): RecursiveScriptModule(original_name=ConvTranspose2d)\n",
       "      (down): RecursiveScriptModule(original_name=Conv2d)\n",
       "      (conv1x1): RecursiveScriptModule(original_name=Conv2d)\n",
       "    )\n",
       "    (maps): RecursiveScriptModule(\n",
       "      original_name=Encoder\n",
       "      (enc): RecursiveScriptModule(\n",
       "        original_name=Sequential\n",
       "        (0): RecursiveScriptModule(\n",
       "          original_name=ConvSC\n",
       "          (conv): RecursiveScriptModule(\n",
       "            original_name=BasicConv2d\n",
       "            (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "            (act): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "          )\n",
       "        )\n",
       "        (1): RecursiveScriptModule(\n",
       "          original_name=ConvSC\n",
       "          (conv): RecursiveScriptModule(\n",
       "            original_name=BasicConv2d\n",
       "            (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "            (act): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dynamics): RecursiveScriptModule(\n",
       "      original_name=TeDev\n",
       "      (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (enc): RecursiveScriptModule(\n",
       "        original_name=Sequential\n",
       "        (0): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (blocks): RecursiveScriptModule(\n",
       "        original_name=ModuleList\n",
       "        (0): RecursiveScriptModule(\n",
       "          original_name=FourierNetBlock\n",
       "          (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (filter): RecursiveScriptModule(\n",
       "            original_name=AdativeFourierNeuralOperator\n",
       "            (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "            (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "          )\n",
       "          (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "          (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=Mlp\n",
       "            (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "            (act): RecursiveScriptModule(original_name=GELU)\n",
       "            (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "            (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "            (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (1): RecursiveScriptModule(\n",
       "          original_name=FourierNetBlock\n",
       "          (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (filter): RecursiveScriptModule(\n",
       "            original_name=AdativeFourierNeuralOperator\n",
       "            (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "            (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "          )\n",
       "          (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "          (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=Mlp\n",
       "            (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "            (act): RecursiveScriptModule(original_name=GELU)\n",
       "            (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "            (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "            (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (2): RecursiveScriptModule(\n",
       "          original_name=FourierNetBlock\n",
       "          (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (filter): RecursiveScriptModule(\n",
       "            original_name=AdativeFourierNeuralOperator\n",
       "            (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "            (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "          )\n",
       "          (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "          (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=Mlp\n",
       "            (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "            (act): RecursiveScriptModule(original_name=GELU)\n",
       "            (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "            (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "            (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (3): RecursiveScriptModule(\n",
       "          original_name=FourierNetBlock\n",
       "          (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (filter): RecursiveScriptModule(\n",
       "            original_name=AdativeFourierNeuralOperator\n",
       "            (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "            (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "          )\n",
       "          (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "          (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=Mlp\n",
       "            (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "            (act): RecursiveScriptModule(original_name=GELU)\n",
       "            (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "            (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "            (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (4): RecursiveScriptModule(\n",
       "          original_name=FourierNetBlock\n",
       "          (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (filter): RecursiveScriptModule(\n",
       "            original_name=AdativeFourierNeuralOperator\n",
       "            (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "            (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "          )\n",
       "          (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "          (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=Mlp\n",
       "            (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "            (act): RecursiveScriptModule(original_name=GELU)\n",
       "            (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "            (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "            (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (5): RecursiveScriptModule(\n",
       "          original_name=FourierNetBlock\n",
       "          (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (filter): RecursiveScriptModule(\n",
       "            original_name=AdativeFourierNeuralOperator\n",
       "            (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "            (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "          )\n",
       "          (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "          (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=Mlp\n",
       "            (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "            (act): RecursiveScriptModule(original_name=GELU)\n",
       "            (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "            (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "            (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (6): RecursiveScriptModule(\n",
       "          original_name=FourierNetBlock\n",
       "          (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (filter): RecursiveScriptModule(\n",
       "            original_name=AdativeFourierNeuralOperator\n",
       "            (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "            (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "          )\n",
       "          (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "          (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=Mlp\n",
       "            (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "            (act): RecursiveScriptModule(original_name=GELU)\n",
       "            (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "            (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "            (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (7): RecursiveScriptModule(\n",
       "          original_name=FourierNetBlock\n",
       "          (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (filter): RecursiveScriptModule(\n",
       "            original_name=AdativeFourierNeuralOperator\n",
       "            (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "            (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "          )\n",
       "          (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "          (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=Mlp\n",
       "            (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "            (act): RecursiveScriptModule(original_name=GELU)\n",
       "            (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "            (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "            (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (8): RecursiveScriptModule(\n",
       "          original_name=FourierNetBlock\n",
       "          (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (filter): RecursiveScriptModule(\n",
       "            original_name=AdativeFourierNeuralOperator\n",
       "            (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "            (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "          )\n",
       "          (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "          (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=Mlp\n",
       "            (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "            (act): RecursiveScriptModule(original_name=GELU)\n",
       "            (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "            (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "            (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (9): RecursiveScriptModule(\n",
       "          original_name=FourierNetBlock\n",
       "          (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (filter): RecursiveScriptModule(\n",
       "            original_name=AdativeFourierNeuralOperator\n",
       "            (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "            (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "          )\n",
       "          (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "          (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=Mlp\n",
       "            (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "            (act): RecursiveScriptModule(original_name=GELU)\n",
       "            (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "            (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "            (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (10): RecursiveScriptModule(\n",
       "          original_name=FourierNetBlock\n",
       "          (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (filter): RecursiveScriptModule(\n",
       "            original_name=AdativeFourierNeuralOperator\n",
       "            (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "            (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "          )\n",
       "          (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "          (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=Mlp\n",
       "            (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "            (act): RecursiveScriptModule(original_name=GELU)\n",
       "            (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "            (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "            (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (11): RecursiveScriptModule(\n",
       "          original_name=FourierNetBlock\n",
       "          (normlayer1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (filter): RecursiveScriptModule(\n",
       "            original_name=AdativeFourierNeuralOperator\n",
       "            (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "            (bias): RecursiveScriptModule(original_name=Conv1d)\n",
       "          )\n",
       "          (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "          (normlayer2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=Mlp\n",
       "            (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "            (act): RecursiveScriptModule(original_name=GELU)\n",
       "            (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "            (fc3): RecursiveScriptModule(original_name=AdaptiveAvgPool1d)\n",
       "            (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dec): RecursiveScriptModule(\n",
       "        original_name=Sequential\n",
       "        (0): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): RecursiveScriptModule(\n",
       "          original_name=Inception\n",
       "          (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (lls): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (1): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (2): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "            (3): RecursiveScriptModule(\n",
       "              original_name=GroupConv2d\n",
       "              (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "              (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "              (activate): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mapsback): RecursiveScriptModule(\n",
       "      original_name=Decoder\n",
       "      (dec): RecursiveScriptModule(\n",
       "        original_name=Sequential\n",
       "        (0): RecursiveScriptModule(\n",
       "          original_name=ConvSC\n",
       "          (conv): RecursiveScriptModule(\n",
       "            original_name=BasicConv2d\n",
       "            (conv): RecursiveScriptModule(original_name=ConvTranspose2d)\n",
       "            (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "            (act): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "          )\n",
       "        )\n",
       "        (1): RecursiveScriptModule(\n",
       "          original_name=ConvSC\n",
       "          (conv): RecursiveScriptModule(\n",
       "            original_name=BasicConv2d\n",
       "            (conv): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (norm): RecursiveScriptModule(original_name=GroupNorm)\n",
       "            (act): RecursiveScriptModule(original_name=LeakyReLU)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (readout): RecursiveScriptModule(original_name=Conv2d)\n",
       "    )\n",
       "  )\n",
       "  (1): RecursiveScriptModule(original_name=SelectiveFilterLayer)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab633e",
   "metadata": {},
   "source": [
    "Inspect `model` contents — diagnostic snippet below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de291c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(model): <class 'torch.jit._script.RecursiveScriptModule'>\n",
      "hasattr(model, 'state_dict'): True\n",
      "hasattr(model, 'named_parameters'): True\n",
      "state_dict keys sample: ['0.jump.maps.enc.0.conv.conv.weight', '0.jump.maps.enc.0.conv.conv.bias', '0.jump.maps.enc.0.conv.norm.weight', '0.jump.maps.enc.0.conv.norm.bias', '0.jump.maps.enc.1.conv.conv.weight', '0.jump.maps.enc.1.conv.conv.bias', '0.jump.maps.enc.1.conv.norm.weight', '0.jump.maps.enc.1.conv.norm.bias', '0.jump.maps.enc.2.conv.conv.weight', '0.jump.maps.enc.2.conv.conv.bias', '0.jump.maps.enc.2.conv.norm.weight', '0.jump.maps.enc.2.conv.norm.bias', '0.jump.maps.enc.3.conv.conv.weight', '0.jump.maps.enc.3.conv.conv.bias', '0.jump.maps.enc.3.conv.norm.weight', '0.jump.maps.enc.3.conv.norm.bias', '0.jump.mmb.enc.0.conv1.weight', '0.jump.mmb.enc.0.conv1.bias', '0.jump.mmb.enc.0.lls.0.conv.weight', '0.jump.mmb.enc.0.lls.0.conv.bias']\n",
      "state_dict len: 1033\n",
      "sample named_parameters: ['0.jump.maps.enc.0.conv.conv.weight', '0.jump.maps.enc.0.conv.conv.bias', '0.jump.maps.enc.0.conv.norm.weight', '0.jump.maps.enc.0.conv.norm.bias', '0.jump.maps.enc.1.conv.conv.weight', '0.jump.maps.enc.1.conv.conv.bias', '0.jump.maps.enc.1.conv.norm.weight', '0.jump.maps.enc.1.conv.norm.bias', '0.jump.maps.enc.2.conv.conv.weight', '0.jump.maps.enc.2.conv.conv.bias', '0.jump.maps.enc.2.conv.norm.weight', '0.jump.maps.enc.2.conv.norm.bias', '0.jump.maps.enc.3.conv.conv.weight', '0.jump.maps.enc.3.conv.conv.bias', '0.jump.maps.enc.3.conv.norm.weight', '0.jump.maps.enc.3.conv.norm.bias', '0.jump.mmb.enc.0.conv1.weight', '0.jump.mmb.enc.0.conv1.bias', '0.jump.mmb.enc.0.lls.0.conv.weight', '0.jump.mmb.enc.0.lls.0.conv.bias']\n",
      "sample named_buffers: []\n"
     ]
    }
   ],
   "source": [
    "# diagnostic\n",
    "print(\"type(model):\", type(model))\n",
    "print(\"hasattr(model, 'state_dict'):\", hasattr(model, 'state_dict'))\n",
    "print(\"hasattr(model, 'named_parameters'):\", hasattr(model, 'named_parameters'))\n",
    "try:\n",
    "    sd = model.state_dict()\n",
    "    print(\"state_dict keys sample:\", list(sd.keys())[:20])\n",
    "    print(\"state_dict len:\", len(sd))\n",
    "except Exception as e:\n",
    "    print(\"state_dict() not usable:\", e)\n",
    "\n",
    "# also inspect a sample of named parameters/buffers\n",
    "if hasattr(model, 'named_parameters'):\n",
    "    print(\"sample named_parameters:\", [n for n, _ in list(model.named_parameters())[:20]])\n",
    "if hasattr(model, 'named_buffers'):\n",
    "    print(\"sample named_buffers:\", [n for n, _ in list(model.named_buffers())[:20]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443b225c",
   "metadata": {},
   "source": [
    "If `state_dict` available: `use new_model.load_state_dict(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71ac7e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.load returned non-dict (it's probably a ScriptModule).\n"
     ]
    }
   ],
   "source": [
    "# try re-loading file as a dict first (safe, no overwrite of 'model' variable)\n",
    "ck = torch.jit.load(model_path, map_location=torch.device('cuda'))\n",
    "if isinstance(ck, dict):\n",
    "    # common wrappers\n",
    "    if 'model_state_dict' in ck:\n",
    "        sd = ck['model_state_dict']\n",
    "    elif 'state_dict' in ck:\n",
    "        sd = ck['state_dict']\n",
    "    else:\n",
    "        sd = ck\n",
    "    # Attempt to load\n",
    "    missing, unexpected = new_model.load_state_dict(sd, strict=False)\n",
    "    print(\"missing keys:\", missing)\n",
    "    print(\"unexpected keys:\", unexpected)\n",
    "else:\n",
    "    print(\"torch.load returned non-dict (it's probably a ScriptModule).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6655d94",
   "metadata": {},
   "source": [
    "If `model.state_dict()` is available (ScriptModule may support this), try direct load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f439f3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded state_dict -> missing: ['space.norm.weight', 'space.norm.bias', 'space.enc.0.conv1.weight', 'space.enc.0.conv1.bias', 'space.enc.0.lls.0.conv.weight', 'space.enc.0.lls.0.conv.bias', 'space.enc.0.lls.0.norm.weight', 'space.enc.0.lls.0.norm.bias', 'space.enc.0.lls.1.conv.weight', 'space.enc.0.lls.1.conv.bias', 'space.enc.0.lls.1.norm.weight', 'space.enc.0.lls.1.norm.bias', 'space.enc.0.lls.2.conv.weight', 'space.enc.0.lls.2.conv.bias', 'space.enc.0.lls.2.norm.weight', 'space.enc.0.lls.2.norm.bias', 'space.enc.1.conv1.weight', 'space.enc.1.conv1.bias', 'space.enc.1.lls.0.conv.weight', 'space.enc.1.lls.0.conv.bias', 'space.enc.1.lls.0.norm.weight', 'space.enc.1.lls.0.norm.bias', 'space.enc.1.lls.1.conv.weight', 'space.enc.1.lls.1.conv.bias', 'space.enc.1.lls.1.norm.weight', 'space.enc.1.lls.1.norm.bias', 'space.enc.1.lls.2.conv.weight', 'space.enc.1.lls.2.conv.bias', 'space.enc.1.lls.2.norm.weight', 'space.enc.1.lls.2.norm.bias', 'space.enc.2.conv1.weight', 'space.enc.2.conv1.bias', 'space.enc.2.lls.0.conv.weight', 'space.enc.2.lls.0.conv.bias', 'space.enc.2.lls.0.norm.weight', 'space.enc.2.lls.0.norm.bias', 'space.enc.2.lls.1.conv.weight', 'space.enc.2.lls.1.conv.bias', 'space.enc.2.lls.1.norm.weight', 'space.enc.2.lls.1.norm.bias', 'space.enc.2.lls.2.conv.weight', 'space.enc.2.lls.2.conv.bias', 'space.enc.2.lls.2.norm.weight', 'space.enc.2.lls.2.norm.bias', 'space.enc.3.conv1.weight', 'space.enc.3.conv1.bias', 'space.enc.3.lls.0.conv.weight', 'space.enc.3.lls.0.conv.bias', 'space.enc.3.lls.0.norm.weight', 'space.enc.3.lls.0.norm.bias', 'space.enc.3.lls.1.conv.weight', 'space.enc.3.lls.1.conv.bias', 'space.enc.3.lls.1.norm.weight', 'space.enc.3.lls.1.norm.bias', 'space.enc.3.lls.2.conv.weight', 'space.enc.3.lls.2.conv.bias', 'space.enc.3.lls.2.norm.weight', 'space.enc.3.lls.2.norm.bias', 'space.enc.4.conv1.weight', 'space.enc.4.conv1.bias', 'space.enc.4.lls.0.conv.weight', 'space.enc.4.lls.0.conv.bias', 'space.enc.4.lls.0.norm.weight', 'space.enc.4.lls.0.norm.bias', 'space.enc.4.lls.1.conv.weight', 'space.enc.4.lls.1.conv.bias', 'space.enc.4.lls.1.norm.weight', 'space.enc.4.lls.1.norm.bias', 'space.enc.4.lls.2.conv.weight', 'space.enc.4.lls.2.conv.bias', 'space.enc.4.lls.2.norm.weight', 'space.enc.4.lls.2.norm.bias', 'space.enc.5.conv1.weight', 'space.enc.5.conv1.bias', 'space.enc.5.lls.0.conv.weight', 'space.enc.5.lls.0.conv.bias', 'space.enc.5.lls.0.norm.weight', 'space.enc.5.lls.0.norm.bias', 'space.enc.5.lls.1.conv.weight', 'space.enc.5.lls.1.conv.bias', 'space.enc.5.lls.1.norm.weight', 'space.enc.5.lls.1.norm.bias', 'space.enc.5.lls.2.conv.weight', 'space.enc.5.lls.2.conv.bias', 'space.enc.5.lls.2.norm.weight', 'space.enc.5.lls.2.norm.bias', 'space.enc.6.conv1.weight', 'space.enc.6.conv1.bias', 'space.enc.6.lls.0.conv.weight', 'space.enc.6.lls.0.conv.bias', 'space.enc.6.lls.0.norm.weight', 'space.enc.6.lls.0.norm.bias', 'space.enc.6.lls.1.conv.weight', 'space.enc.6.lls.1.conv.bias', 'space.enc.6.lls.1.norm.weight', 'space.enc.6.lls.1.norm.bias', 'space.enc.6.lls.2.conv.weight', 'space.enc.6.lls.2.conv.bias', 'space.enc.6.lls.2.norm.weight', 'space.enc.6.lls.2.norm.bias', 'space.enc.7.conv1.weight', 'space.enc.7.conv1.bias', 'space.enc.7.lls.0.conv.weight', 'space.enc.7.lls.0.conv.bias', 'space.enc.7.lls.0.norm.weight', 'space.enc.7.lls.0.norm.bias', 'space.enc.7.lls.1.conv.weight', 'space.enc.7.lls.1.conv.bias', 'space.enc.7.lls.1.norm.weight', 'space.enc.7.lls.1.norm.bias', 'space.enc.7.lls.2.conv.weight', 'space.enc.7.lls.2.conv.bias', 'space.enc.7.lls.2.norm.weight', 'space.enc.7.lls.2.norm.bias', 'space.blocks.0.normlayer1.weight', 'space.blocks.0.normlayer1.bias', 'space.blocks.0.filter.w1', 'space.blocks.0.filter.b1', 'space.blocks.0.filter.w2', 'space.blocks.0.filter.b2', 'space.blocks.0.filter.bias.weight', 'space.blocks.0.filter.bias.bias', 'space.blocks.0.attn.multihead_attn.in_proj_weight', 'space.blocks.0.attn.multihead_attn.in_proj_bias', 'space.blocks.0.attn.multihead_attn.out_proj.weight', 'space.blocks.0.attn.multihead_attn.out_proj.bias', 'space.blocks.0.normlayer2.weight', 'space.blocks.0.normlayer2.bias', 'space.blocks.0.mlp.fc1.weight', 'space.blocks.0.mlp.fc1.bias', 'space.blocks.0.mlp.fc2.weight', 'space.blocks.0.mlp.fc2.bias', 'space.blocks.1.normlayer1.weight', 'space.blocks.1.normlayer1.bias', 'space.blocks.1.filter.w1', 'space.blocks.1.filter.b1', 'space.blocks.1.filter.w2', 'space.blocks.1.filter.b2', 'space.blocks.1.filter.bias.weight', 'space.blocks.1.filter.bias.bias', 'space.blocks.1.attn.multihead_attn.in_proj_weight', 'space.blocks.1.attn.multihead_attn.in_proj_bias', 'space.blocks.1.attn.multihead_attn.out_proj.weight', 'space.blocks.1.attn.multihead_attn.out_proj.bias', 'space.blocks.1.normlayer2.weight', 'space.blocks.1.normlayer2.bias', 'space.blocks.1.mlp.fc1.weight', 'space.blocks.1.mlp.fc1.bias', 'space.blocks.1.mlp.fc2.weight', 'space.blocks.1.mlp.fc2.bias', 'space.blocks.2.normlayer1.weight', 'space.blocks.2.normlayer1.bias', 'space.blocks.2.filter.w1', 'space.blocks.2.filter.b1', 'space.blocks.2.filter.w2', 'space.blocks.2.filter.b2', 'space.blocks.2.filter.bias.weight', 'space.blocks.2.filter.bias.bias', 'space.blocks.2.attn.multihead_attn.in_proj_weight', 'space.blocks.2.attn.multihead_attn.in_proj_bias', 'space.blocks.2.attn.multihead_attn.out_proj.weight', 'space.blocks.2.attn.multihead_attn.out_proj.bias', 'space.blocks.2.normlayer2.weight', 'space.blocks.2.normlayer2.bias', 'space.blocks.2.mlp.fc1.weight', 'space.blocks.2.mlp.fc1.bias', 'space.blocks.2.mlp.fc2.weight', 'space.blocks.2.mlp.fc2.bias', 'space.blocks.3.normlayer1.weight', 'space.blocks.3.normlayer1.bias', 'space.blocks.3.filter.w1', 'space.blocks.3.filter.b1', 'space.blocks.3.filter.w2', 'space.blocks.3.filter.b2', 'space.blocks.3.filter.bias.weight', 'space.blocks.3.filter.bias.bias', 'space.blocks.3.attn.multihead_attn.in_proj_weight', 'space.blocks.3.attn.multihead_attn.in_proj_bias', 'space.blocks.3.attn.multihead_attn.out_proj.weight', 'space.blocks.3.attn.multihead_attn.out_proj.bias', 'space.blocks.3.normlayer2.weight', 'space.blocks.3.normlayer2.bias', 'space.blocks.3.mlp.fc1.weight', 'space.blocks.3.mlp.fc1.bias', 'space.blocks.3.mlp.fc2.weight', 'space.blocks.3.mlp.fc2.bias', 'space.blocks.4.normlayer1.weight', 'space.blocks.4.normlayer1.bias', 'space.blocks.4.filter.w1', 'space.blocks.4.filter.b1', 'space.blocks.4.filter.w2', 'space.blocks.4.filter.b2', 'space.blocks.4.filter.bias.weight', 'space.blocks.4.filter.bias.bias', 'space.blocks.4.attn.multihead_attn.in_proj_weight', 'space.blocks.4.attn.multihead_attn.in_proj_bias', 'space.blocks.4.attn.multihead_attn.out_proj.weight', 'space.blocks.4.attn.multihead_attn.out_proj.bias', 'space.blocks.4.normlayer2.weight', 'space.blocks.4.normlayer2.bias', 'space.blocks.4.mlp.fc1.weight', 'space.blocks.4.mlp.fc1.bias', 'space.blocks.4.mlp.fc2.weight', 'space.blocks.4.mlp.fc2.bias', 'space.blocks.5.normlayer1.weight', 'space.blocks.5.normlayer1.bias', 'space.blocks.5.filter.w1', 'space.blocks.5.filter.b1', 'space.blocks.5.filter.w2', 'space.blocks.5.filter.b2', 'space.blocks.5.filter.bias.weight', 'space.blocks.5.filter.bias.bias', 'space.blocks.5.attn.multihead_attn.in_proj_weight', 'space.blocks.5.attn.multihead_attn.in_proj_bias', 'space.blocks.5.attn.multihead_attn.out_proj.weight', 'space.blocks.5.attn.multihead_attn.out_proj.bias', 'space.blocks.5.normlayer2.weight', 'space.blocks.5.normlayer2.bias', 'space.blocks.5.mlp.fc1.weight', 'space.blocks.5.mlp.fc1.bias', 'space.blocks.5.mlp.fc2.weight', 'space.blocks.5.mlp.fc2.bias', 'space.blocks.6.normlayer1.weight', 'space.blocks.6.normlayer1.bias', 'space.blocks.6.filter.w1', 'space.blocks.6.filter.b1', 'space.blocks.6.filter.w2', 'space.blocks.6.filter.b2', 'space.blocks.6.filter.bias.weight', 'space.blocks.6.filter.bias.bias', 'space.blocks.6.attn.multihead_attn.in_proj_weight', 'space.blocks.6.attn.multihead_attn.in_proj_bias', 'space.blocks.6.attn.multihead_attn.out_proj.weight', 'space.blocks.6.attn.multihead_attn.out_proj.bias', 'space.blocks.6.normlayer2.weight', 'space.blocks.6.normlayer2.bias', 'space.blocks.6.mlp.fc1.weight', 'space.blocks.6.mlp.fc1.bias', 'space.blocks.6.mlp.fc2.weight', 'space.blocks.6.mlp.fc2.bias', 'space.blocks.7.normlayer1.weight', 'space.blocks.7.normlayer1.bias', 'space.blocks.7.filter.w1', 'space.blocks.7.filter.b1', 'space.blocks.7.filter.w2', 'space.blocks.7.filter.b2', 'space.blocks.7.filter.bias.weight', 'space.blocks.7.filter.bias.bias', 'space.blocks.7.attn.multihead_attn.in_proj_weight', 'space.blocks.7.attn.multihead_attn.in_proj_bias', 'space.blocks.7.attn.multihead_attn.out_proj.weight', 'space.blocks.7.attn.multihead_attn.out_proj.bias', 'space.blocks.7.normlayer2.weight', 'space.blocks.7.normlayer2.bias', 'space.blocks.7.mlp.fc1.weight', 'space.blocks.7.mlp.fc1.bias', 'space.blocks.7.mlp.fc2.weight', 'space.blocks.7.mlp.fc2.bias', 'space.blocks.8.normlayer1.weight', 'space.blocks.8.normlayer1.bias', 'space.blocks.8.filter.w1', 'space.blocks.8.filter.b1', 'space.blocks.8.filter.w2', 'space.blocks.8.filter.b2', 'space.blocks.8.filter.bias.weight', 'space.blocks.8.filter.bias.bias', 'space.blocks.8.attn.multihead_attn.in_proj_weight', 'space.blocks.8.attn.multihead_attn.in_proj_bias', 'space.blocks.8.attn.multihead_attn.out_proj.weight', 'space.blocks.8.attn.multihead_attn.out_proj.bias', 'space.blocks.8.normlayer2.weight', 'space.blocks.8.normlayer2.bias', 'space.blocks.8.mlp.fc1.weight', 'space.blocks.8.mlp.fc1.bias', 'space.blocks.8.mlp.fc2.weight', 'space.blocks.8.mlp.fc2.bias', 'space.blocks.9.normlayer1.weight', 'space.blocks.9.normlayer1.bias', 'space.blocks.9.filter.w1', 'space.blocks.9.filter.b1', 'space.blocks.9.filter.w2', 'space.blocks.9.filter.b2', 'space.blocks.9.filter.bias.weight', 'space.blocks.9.filter.bias.bias', 'space.blocks.9.attn.multihead_attn.in_proj_weight', 'space.blocks.9.attn.multihead_attn.in_proj_bias', 'space.blocks.9.attn.multihead_attn.out_proj.weight', 'space.blocks.9.attn.multihead_attn.out_proj.bias', 'space.blocks.9.normlayer2.weight', 'space.blocks.9.normlayer2.bias', 'space.blocks.9.mlp.fc1.weight', 'space.blocks.9.mlp.fc1.bias', 'space.blocks.9.mlp.fc2.weight', 'space.blocks.9.mlp.fc2.bias', 'space.blocks.10.normlayer1.weight', 'space.blocks.10.normlayer1.bias', 'space.blocks.10.filter.w1', 'space.blocks.10.filter.b1', 'space.blocks.10.filter.w2', 'space.blocks.10.filter.b2', 'space.blocks.10.filter.bias.weight', 'space.blocks.10.filter.bias.bias', 'space.blocks.10.attn.multihead_attn.in_proj_weight', 'space.blocks.10.attn.multihead_attn.in_proj_bias', 'space.blocks.10.attn.multihead_attn.out_proj.weight', 'space.blocks.10.attn.multihead_attn.out_proj.bias', 'space.blocks.10.normlayer2.weight', 'space.blocks.10.normlayer2.bias', 'space.blocks.10.mlp.fc1.weight', 'space.blocks.10.mlp.fc1.bias', 'space.blocks.10.mlp.fc2.weight', 'space.blocks.10.mlp.fc2.bias', 'space.blocks.11.normlayer1.weight', 'space.blocks.11.normlayer1.bias', 'space.blocks.11.filter.w1', 'space.blocks.11.filter.b1', 'space.blocks.11.filter.w2', 'space.blocks.11.filter.b2', 'space.blocks.11.filter.bias.weight', 'space.blocks.11.filter.bias.bias', 'space.blocks.11.attn.multihead_attn.in_proj_weight', 'space.blocks.11.attn.multihead_attn.in_proj_bias', 'space.blocks.11.attn.multihead_attn.out_proj.weight', 'space.blocks.11.attn.multihead_attn.out_proj.bias', 'space.blocks.11.normlayer2.weight', 'space.blocks.11.normlayer2.bias', 'space.blocks.11.mlp.fc1.weight', 'space.blocks.11.mlp.fc1.bias', 'space.blocks.11.mlp.fc2.weight', 'space.blocks.11.mlp.fc2.bias', 'space.dec.0.conv1.weight', 'space.dec.0.conv1.bias', 'space.dec.0.lls.0.conv.weight', 'space.dec.0.lls.0.conv.bias', 'space.dec.0.lls.0.norm.weight', 'space.dec.0.lls.0.norm.bias', 'space.dec.0.lls.1.conv.weight', 'space.dec.0.lls.1.conv.bias', 'space.dec.0.lls.1.norm.weight', 'space.dec.0.lls.1.norm.bias', 'space.dec.0.lls.2.conv.weight', 'space.dec.0.lls.2.conv.bias', 'space.dec.0.lls.2.norm.weight', 'space.dec.0.lls.2.norm.bias', 'space.dec.1.conv1.weight', 'space.dec.1.conv1.bias', 'space.dec.1.lls.0.conv.weight', 'space.dec.1.lls.0.conv.bias', 'space.dec.1.lls.0.norm.weight', 'space.dec.1.lls.0.norm.bias', 'space.dec.1.lls.1.conv.weight', 'space.dec.1.lls.1.conv.bias', 'space.dec.1.lls.1.norm.weight', 'space.dec.1.lls.1.norm.bias', 'space.dec.1.lls.2.conv.weight', 'space.dec.1.lls.2.conv.bias', 'space.dec.1.lls.2.norm.weight', 'space.dec.1.lls.2.norm.bias', 'space.dec.2.conv1.weight', 'space.dec.2.conv1.bias', 'space.dec.2.lls.0.conv.weight', 'space.dec.2.lls.0.conv.bias', 'space.dec.2.lls.0.norm.weight', 'space.dec.2.lls.0.norm.bias', 'space.dec.2.lls.1.conv.weight', 'space.dec.2.lls.1.conv.bias', 'space.dec.2.lls.1.norm.weight', 'space.dec.2.lls.1.norm.bias', 'space.dec.2.lls.2.conv.weight', 'space.dec.2.lls.2.conv.bias', 'space.dec.2.lls.2.norm.weight', 'space.dec.2.lls.2.norm.bias', 'space.dec.3.conv1.weight', 'space.dec.3.conv1.bias', 'space.dec.3.lls.0.conv.weight', 'space.dec.3.lls.0.conv.bias', 'space.dec.3.lls.0.norm.weight', 'space.dec.3.lls.0.norm.bias', 'space.dec.3.lls.1.conv.weight', 'space.dec.3.lls.1.conv.bias', 'space.dec.3.lls.1.norm.weight', 'space.dec.3.lls.1.norm.bias', 'space.dec.3.lls.2.conv.weight', 'space.dec.3.lls.2.conv.bias', 'space.dec.3.lls.2.norm.weight', 'space.dec.3.lls.2.norm.bias', 'space.dec.4.conv1.weight', 'space.dec.4.conv1.bias', 'space.dec.4.lls.0.conv.weight', 'space.dec.4.lls.0.conv.bias', 'space.dec.4.lls.0.norm.weight', 'space.dec.4.lls.0.norm.bias', 'space.dec.4.lls.1.conv.weight', 'space.dec.4.lls.1.conv.bias', 'space.dec.4.lls.1.norm.weight', 'space.dec.4.lls.1.norm.bias', 'space.dec.4.lls.2.conv.weight', 'space.dec.4.lls.2.conv.bias', 'space.dec.4.lls.2.norm.weight', 'space.dec.4.lls.2.norm.bias', 'space.dec.5.conv1.weight', 'space.dec.5.conv1.bias', 'space.dec.5.lls.0.conv.weight', 'space.dec.5.lls.0.conv.bias', 'space.dec.5.lls.0.norm.weight', 'space.dec.5.lls.0.norm.bias', 'space.dec.5.lls.1.conv.weight', 'space.dec.5.lls.1.conv.bias', 'space.dec.5.lls.1.norm.weight', 'space.dec.5.lls.1.norm.bias', 'space.dec.5.lls.2.conv.weight', 'space.dec.5.lls.2.conv.bias', 'space.dec.5.lls.2.norm.weight', 'space.dec.5.lls.2.norm.bias', 'space.dec.6.conv1.weight', 'space.dec.6.conv1.bias', 'space.dec.6.lls.0.conv.weight', 'space.dec.6.lls.0.conv.bias', 'space.dec.6.lls.0.norm.weight', 'space.dec.6.lls.0.norm.bias', 'space.dec.6.lls.1.conv.weight', 'space.dec.6.lls.1.conv.bias', 'space.dec.6.lls.1.norm.weight', 'space.dec.6.lls.1.norm.bias', 'space.dec.6.lls.2.conv.weight', 'space.dec.6.lls.2.conv.bias', 'space.dec.6.lls.2.norm.weight', 'space.dec.6.lls.2.norm.bias', 'space.dec.7.conv1.weight', 'space.dec.7.conv1.bias', 'space.dec.7.lls.0.conv.weight', 'space.dec.7.lls.0.conv.bias', 'space.dec.7.lls.0.norm.weight', 'space.dec.7.lls.0.norm.bias', 'space.dec.7.lls.1.conv.weight', 'space.dec.7.lls.1.conv.bias', 'space.dec.7.lls.1.norm.weight', 'space.dec.7.lls.1.norm.bias', 'space.dec.7.lls.2.conv.weight', 'space.dec.7.lls.2.conv.bias', 'space.dec.7.lls.2.norm.weight', 'space.dec.7.lls.2.norm.bias', 'dynamics.NN.upconv.weight', 'dynamics.NN.upconv.bias', 'dynamics.NO.pos_embed', 'dynamics.NO.patch_embed.projection.weight', 'dynamics.NO.patch_embed.projection.bias', 'dynamics.NO.blks.0.normlayer1.weight', 'dynamics.NO.blks.0.normlayer1.bias', 'dynamics.NO.blks.0.filter.w1', 'dynamics.NO.blks.0.filter.b1', 'dynamics.NO.blks.0.filter.w2', 'dynamics.NO.blks.0.filter.b2', 'dynamics.NO.blks.0.filter.bias.weight', 'dynamics.NO.blks.0.filter.bias.bias', 'dynamics.NO.blks.0.attn.multihead_attn.in_proj_weight', 'dynamics.NO.blks.0.attn.multihead_attn.in_proj_bias', 'dynamics.NO.blks.0.attn.multihead_attn.out_proj.weight', 'dynamics.NO.blks.0.attn.multihead_attn.out_proj.bias', 'dynamics.NO.blks.0.normlayer2.weight', 'dynamics.NO.blks.0.normlayer2.bias', 'dynamics.NO.blks.0.mlp.fc1.weight', 'dynamics.NO.blks.0.mlp.fc1.bias', 'dynamics.NO.blks.0.mlp.fc2.weight', 'dynamics.NO.blks.0.mlp.fc2.bias', 'dynamics.NO.blks.1.normlayer1.weight', 'dynamics.NO.blks.1.normlayer1.bias', 'dynamics.NO.blks.1.filter.w1', 'dynamics.NO.blks.1.filter.b1', 'dynamics.NO.blks.1.filter.w2', 'dynamics.NO.blks.1.filter.b2', 'dynamics.NO.blks.1.filter.bias.weight', 'dynamics.NO.blks.1.filter.bias.bias', 'dynamics.NO.blks.1.attn.multihead_attn.in_proj_weight', 'dynamics.NO.blks.1.attn.multihead_attn.in_proj_bias', 'dynamics.NO.blks.1.attn.multihead_attn.out_proj.weight', 'dynamics.NO.blks.1.attn.multihead_attn.out_proj.bias', 'dynamics.NO.blks.1.normlayer2.weight', 'dynamics.NO.blks.1.normlayer2.bias', 'dynamics.NO.blks.1.mlp.fc1.weight', 'dynamics.NO.blks.1.mlp.fc1.bias', 'dynamics.NO.blks.1.mlp.fc2.weight', 'dynamics.NO.blks.1.mlp.fc2.bias', 'dynamics.NO.blks.2.normlayer1.weight', 'dynamics.NO.blks.2.normlayer1.bias', 'dynamics.NO.blks.2.filter.w1', 'dynamics.NO.blks.2.filter.b1', 'dynamics.NO.blks.2.filter.w2', 'dynamics.NO.blks.2.filter.b2', 'dynamics.NO.blks.2.filter.bias.weight', 'dynamics.NO.blks.2.filter.bias.bias', 'dynamics.NO.blks.2.attn.multihead_attn.in_proj_weight', 'dynamics.NO.blks.2.attn.multihead_attn.in_proj_bias', 'dynamics.NO.blks.2.attn.multihead_attn.out_proj.weight', 'dynamics.NO.blks.2.attn.multihead_attn.out_proj.bias', 'dynamics.NO.blks.2.normlayer2.weight', 'dynamics.NO.blks.2.normlayer2.bias', 'dynamics.NO.blks.2.mlp.fc1.weight', 'dynamics.NO.blks.2.mlp.fc1.bias', 'dynamics.NO.blks.2.mlp.fc2.weight', 'dynamics.NO.blks.2.mlp.fc2.bias', 'dynamics.NO.blks.3.normlayer1.weight', 'dynamics.NO.blks.3.normlayer1.bias', 'dynamics.NO.blks.3.filter.w1', 'dynamics.NO.blks.3.filter.b1', 'dynamics.NO.blks.3.filter.w2', 'dynamics.NO.blks.3.filter.b2', 'dynamics.NO.blks.3.filter.bias.weight', 'dynamics.NO.blks.3.filter.bias.bias', 'dynamics.NO.blks.3.attn.multihead_attn.in_proj_weight', 'dynamics.NO.blks.3.attn.multihead_attn.in_proj_bias', 'dynamics.NO.blks.3.attn.multihead_attn.out_proj.weight', 'dynamics.NO.blks.3.attn.multihead_attn.out_proj.bias', 'dynamics.NO.blks.3.normlayer2.weight', 'dynamics.NO.blks.3.normlayer2.bias', 'dynamics.NO.blks.3.mlp.fc1.weight', 'dynamics.NO.blks.3.mlp.fc1.bias', 'dynamics.NO.blks.3.mlp.fc2.weight', 'dynamics.NO.blks.3.mlp.fc2.bias', 'dynamics.NO.blks.4.normlayer1.weight', 'dynamics.NO.blks.4.normlayer1.bias', 'dynamics.NO.blks.4.filter.w1', 'dynamics.NO.blks.4.filter.b1', 'dynamics.NO.blks.4.filter.w2', 'dynamics.NO.blks.4.filter.b2', 'dynamics.NO.blks.4.filter.bias.weight', 'dynamics.NO.blks.4.filter.bias.bias', 'dynamics.NO.blks.4.attn.multihead_attn.in_proj_weight', 'dynamics.NO.blks.4.attn.multihead_attn.in_proj_bias', 'dynamics.NO.blks.4.attn.multihead_attn.out_proj.weight', 'dynamics.NO.blks.4.attn.multihead_attn.out_proj.bias', 'dynamics.NO.blks.4.normlayer2.weight', 'dynamics.NO.blks.4.normlayer2.bias', 'dynamics.NO.blks.4.mlp.fc1.weight', 'dynamics.NO.blks.4.mlp.fc1.bias', 'dynamics.NO.blks.4.mlp.fc2.weight', 'dynamics.NO.blks.4.mlp.fc2.bias', 'dynamics.NO.blks.5.normlayer1.weight', 'dynamics.NO.blks.5.normlayer1.bias', 'dynamics.NO.blks.5.filter.w1', 'dynamics.NO.blks.5.filter.b1', 'dynamics.NO.blks.5.filter.w2', 'dynamics.NO.blks.5.filter.b2', 'dynamics.NO.blks.5.filter.bias.weight', 'dynamics.NO.blks.5.filter.bias.bias', 'dynamics.NO.blks.5.attn.multihead_attn.in_proj_weight', 'dynamics.NO.blks.5.attn.multihead_attn.in_proj_bias', 'dynamics.NO.blks.5.attn.multihead_attn.out_proj.weight', 'dynamics.NO.blks.5.attn.multihead_attn.out_proj.bias', 'dynamics.NO.blks.5.normlayer2.weight', 'dynamics.NO.blks.5.normlayer2.bias', 'dynamics.NO.blks.5.mlp.fc1.weight', 'dynamics.NO.blks.5.mlp.fc1.bias', 'dynamics.NO.blks.5.mlp.fc2.weight', 'dynamics.NO.blks.5.mlp.fc2.bias', 'dynamics.NO.blks.6.normlayer1.weight', 'dynamics.NO.blks.6.normlayer1.bias', 'dynamics.NO.blks.6.filter.w1', 'dynamics.NO.blks.6.filter.b1', 'dynamics.NO.blks.6.filter.w2', 'dynamics.NO.blks.6.filter.b2', 'dynamics.NO.blks.6.filter.bias.weight', 'dynamics.NO.blks.6.filter.bias.bias', 'dynamics.NO.blks.6.attn.multihead_attn.in_proj_weight', 'dynamics.NO.blks.6.attn.multihead_attn.in_proj_bias', 'dynamics.NO.blks.6.attn.multihead_attn.out_proj.weight', 'dynamics.NO.blks.6.attn.multihead_attn.out_proj.bias', 'dynamics.NO.blks.6.normlayer2.weight', 'dynamics.NO.blks.6.normlayer2.bias', 'dynamics.NO.blks.6.mlp.fc1.weight', 'dynamics.NO.blks.6.mlp.fc1.bias', 'dynamics.NO.blks.6.mlp.fc2.weight', 'dynamics.NO.blks.6.mlp.fc2.bias', 'dynamics.NO.blks.7.normlayer1.weight', 'dynamics.NO.blks.7.normlayer1.bias', 'dynamics.NO.blks.7.filter.w1', 'dynamics.NO.blks.7.filter.b1', 'dynamics.NO.blks.7.filter.w2', 'dynamics.NO.blks.7.filter.b2', 'dynamics.NO.blks.7.filter.bias.weight', 'dynamics.NO.blks.7.filter.bias.bias', 'dynamics.NO.blks.7.attn.multihead_attn.in_proj_weight', 'dynamics.NO.blks.7.attn.multihead_attn.in_proj_bias', 'dynamics.NO.blks.7.attn.multihead_attn.out_proj.weight', 'dynamics.NO.blks.7.attn.multihead_attn.out_proj.bias', 'dynamics.NO.blks.7.normlayer2.weight', 'dynamics.NO.blks.7.normlayer2.bias', 'dynamics.NO.blks.7.mlp.fc1.weight', 'dynamics.NO.blks.7.mlp.fc1.bias', 'dynamics.NO.blks.7.mlp.fc2.weight', 'dynamics.NO.blks.7.mlp.fc2.bias', 'dynamics.NO.blks.8.normlayer1.weight', 'dynamics.NO.blks.8.normlayer1.bias', 'dynamics.NO.blks.8.filter.w1', 'dynamics.NO.blks.8.filter.b1', 'dynamics.NO.blks.8.filter.w2', 'dynamics.NO.blks.8.filter.b2', 'dynamics.NO.blks.8.filter.bias.weight', 'dynamics.NO.blks.8.filter.bias.bias', 'dynamics.NO.blks.8.attn.multihead_attn.in_proj_weight', 'dynamics.NO.blks.8.attn.multihead_attn.in_proj_bias', 'dynamics.NO.blks.8.attn.multihead_attn.out_proj.weight', 'dynamics.NO.blks.8.attn.multihead_attn.out_proj.bias', 'dynamics.NO.blks.8.normlayer2.weight', 'dynamics.NO.blks.8.normlayer2.bias', 'dynamics.NO.blks.8.mlp.fc1.weight', 'dynamics.NO.blks.8.mlp.fc1.bias', 'dynamics.NO.blks.8.mlp.fc2.weight', 'dynamics.NO.blks.8.mlp.fc2.bias', 'dynamics.NO.blks.9.normlayer1.weight', 'dynamics.NO.blks.9.normlayer1.bias', 'dynamics.NO.blks.9.filter.w1', 'dynamics.NO.blks.9.filter.b1', 'dynamics.NO.blks.9.filter.w2', 'dynamics.NO.blks.9.filter.b2', 'dynamics.NO.blks.9.filter.bias.weight', 'dynamics.NO.blks.9.filter.bias.bias', 'dynamics.NO.blks.9.attn.multihead_attn.in_proj_weight', 'dynamics.NO.blks.9.attn.multihead_attn.in_proj_bias', 'dynamics.NO.blks.9.attn.multihead_attn.out_proj.weight', 'dynamics.NO.blks.9.attn.multihead_attn.out_proj.bias', 'dynamics.NO.blks.9.normlayer2.weight', 'dynamics.NO.blks.9.normlayer2.bias', 'dynamics.NO.blks.9.mlp.fc1.weight', 'dynamics.NO.blks.9.mlp.fc1.bias', 'dynamics.NO.blks.9.mlp.fc2.weight', 'dynamics.NO.blks.9.mlp.fc2.bias', 'dynamics.NO.blks.10.normlayer1.weight', 'dynamics.NO.blks.10.normlayer1.bias', 'dynamics.NO.blks.10.filter.w1', 'dynamics.NO.blks.10.filter.b1', 'dynamics.NO.blks.10.filter.w2', 'dynamics.NO.blks.10.filter.b2', 'dynamics.NO.blks.10.filter.bias.weight', 'dynamics.NO.blks.10.filter.bias.bias', 'dynamics.NO.blks.10.attn.multihead_attn.in_proj_weight', 'dynamics.NO.blks.10.attn.multihead_attn.in_proj_bias', 'dynamics.NO.blks.10.attn.multihead_attn.out_proj.weight', 'dynamics.NO.blks.10.attn.multihead_attn.out_proj.bias', 'dynamics.NO.blks.10.normlayer2.weight', 'dynamics.NO.blks.10.normlayer2.bias', 'dynamics.NO.blks.10.mlp.fc1.weight', 'dynamics.NO.blks.10.mlp.fc1.bias', 'dynamics.NO.blks.10.mlp.fc2.weight', 'dynamics.NO.blks.10.mlp.fc2.bias', 'dynamics.NO.blks.11.normlayer1.weight', 'dynamics.NO.blks.11.normlayer1.bias', 'dynamics.NO.blks.11.filter.w1', 'dynamics.NO.blks.11.filter.b1', 'dynamics.NO.blks.11.filter.w2', 'dynamics.NO.blks.11.filter.b2', 'dynamics.NO.blks.11.filter.bias.weight', 'dynamics.NO.blks.11.filter.bias.bias', 'dynamics.NO.blks.11.attn.multihead_attn.in_proj_weight', 'dynamics.NO.blks.11.attn.multihead_attn.in_proj_bias', 'dynamics.NO.blks.11.attn.multihead_attn.out_proj.weight', 'dynamics.NO.blks.11.attn.multihead_attn.out_proj.bias', 'dynamics.NO.blks.11.normlayer2.weight', 'dynamics.NO.blks.11.normlayer2.bias', 'dynamics.NO.blks.11.mlp.fc1.weight', 'dynamics.NO.blks.11.mlp.fc1.bias', 'dynamics.NO.blks.11.mlp.fc2.weight', 'dynamics.NO.blks.11.mlp.fc2.bias', 'dynamics.NO.norm.weight', 'dynamics.NO.norm.bias', 'dynamics.NO.lproj.transposeconv1.weight', 'dynamics.NO.lproj.transposeconv1.bias', 'dynamics.NO.lproj.transposeconv2.weight', 'dynamics.NO.lproj.transposeconv2.bias', 'dynamics.NO.lproj.transposeconv3.weight', 'dynamics.NO.lproj.transposeconv3.bias', 'dynamics.up.weight', 'dynamics.up.bias', 'dynamics.down.weight', 'dynamics.down.bias', 'dynamics.conv1x1.weight', 'dynamics.conv1x1.bias', 'maps.enc.0.conv.conv.weight', 'maps.enc.0.conv.conv.bias', 'maps.enc.0.conv.norm.weight', 'maps.enc.0.conv.norm.bias', 'maps.enc.1.conv.conv.weight', 'maps.enc.1.conv.conv.bias', 'maps.enc.1.conv.norm.weight', 'maps.enc.1.conv.norm.bias', 'mapsback.dec.0.conv.conv.weight', 'mapsback.dec.0.conv.conv.bias', 'mapsback.dec.0.conv.norm.weight', 'mapsback.dec.0.conv.norm.bias', 'mapsback.dec.1.conv.conv.weight', 'mapsback.dec.1.conv.conv.bias', 'mapsback.dec.1.conv.norm.weight', 'mapsback.dec.1.conv.norm.bias', 'mapsback.readout.weight', 'mapsback.readout.bias']  unexpected: ['0.jump.maps.enc.0.conv.conv.weight', '0.jump.maps.enc.0.conv.conv.bias', '0.jump.maps.enc.0.conv.norm.weight', '0.jump.maps.enc.0.conv.norm.bias', '0.jump.maps.enc.1.conv.conv.weight', '0.jump.maps.enc.1.conv.conv.bias', '0.jump.maps.enc.1.conv.norm.weight', '0.jump.maps.enc.1.conv.norm.bias', '0.jump.maps.enc.2.conv.conv.weight', '0.jump.maps.enc.2.conv.conv.bias', '0.jump.maps.enc.2.conv.norm.weight', '0.jump.maps.enc.2.conv.norm.bias', '0.jump.maps.enc.3.conv.conv.weight', '0.jump.maps.enc.3.conv.conv.bias', '0.jump.maps.enc.3.conv.norm.weight', '0.jump.maps.enc.3.conv.norm.bias', '0.jump.mmb.enc.0.conv1.weight', '0.jump.mmb.enc.0.conv1.bias', '0.jump.mmb.enc.0.lls.0.conv.weight', '0.jump.mmb.enc.0.lls.0.conv.bias', '0.jump.mmb.enc.0.lls.0.norm.weight', '0.jump.mmb.enc.0.lls.0.norm.bias', '0.jump.mmb.enc.0.lls.1.conv.weight', '0.jump.mmb.enc.0.lls.1.conv.bias', '0.jump.mmb.enc.0.lls.1.norm.weight', '0.jump.mmb.enc.0.lls.1.norm.bias', '0.jump.mmb.enc.0.lls.2.conv.weight', '0.jump.mmb.enc.0.lls.2.conv.bias', '0.jump.mmb.enc.0.lls.2.norm.weight', '0.jump.mmb.enc.0.lls.2.norm.bias', '0.jump.mmb.enc.0.lls.3.conv.weight', '0.jump.mmb.enc.0.lls.3.conv.bias', '0.jump.mmb.enc.0.lls.3.norm.weight', '0.jump.mmb.enc.0.lls.3.norm.bias', '0.jump.mmb.enc.1.conv1.weight', '0.jump.mmb.enc.1.conv1.bias', '0.jump.mmb.enc.1.lls.0.conv.weight', '0.jump.mmb.enc.1.lls.0.conv.bias', '0.jump.mmb.enc.1.lls.0.norm.weight', '0.jump.mmb.enc.1.lls.0.norm.bias', '0.jump.mmb.enc.1.lls.1.conv.weight', '0.jump.mmb.enc.1.lls.1.conv.bias', '0.jump.mmb.enc.1.lls.1.norm.weight', '0.jump.mmb.enc.1.lls.1.norm.bias', '0.jump.mmb.enc.1.lls.2.conv.weight', '0.jump.mmb.enc.1.lls.2.conv.bias', '0.jump.mmb.enc.1.lls.2.norm.weight', '0.jump.mmb.enc.1.lls.2.norm.bias', '0.jump.mmb.enc.1.lls.3.conv.weight', '0.jump.mmb.enc.1.lls.3.conv.bias', '0.jump.mmb.enc.1.lls.3.norm.weight', '0.jump.mmb.enc.1.lls.3.norm.bias', '0.jump.mmb.enc.2.conv1.weight', '0.jump.mmb.enc.2.conv1.bias', '0.jump.mmb.enc.2.lls.0.conv.weight', '0.jump.mmb.enc.2.lls.0.conv.bias', '0.jump.mmb.enc.2.lls.0.norm.weight', '0.jump.mmb.enc.2.lls.0.norm.bias', '0.jump.mmb.enc.2.lls.1.conv.weight', '0.jump.mmb.enc.2.lls.1.conv.bias', '0.jump.mmb.enc.2.lls.1.norm.weight', '0.jump.mmb.enc.2.lls.1.norm.bias', '0.jump.mmb.enc.2.lls.2.conv.weight', '0.jump.mmb.enc.2.lls.2.conv.bias', '0.jump.mmb.enc.2.lls.2.norm.weight', '0.jump.mmb.enc.2.lls.2.norm.bias', '0.jump.mmb.enc.2.lls.3.conv.weight', '0.jump.mmb.enc.2.lls.3.conv.bias', '0.jump.mmb.enc.2.lls.3.norm.weight', '0.jump.mmb.enc.2.lls.3.norm.bias', '0.jump.mmb.enc.3.conv1.weight', '0.jump.mmb.enc.3.conv1.bias', '0.jump.mmb.enc.3.lls.0.conv.weight', '0.jump.mmb.enc.3.lls.0.conv.bias', '0.jump.mmb.enc.3.lls.0.norm.weight', '0.jump.mmb.enc.3.lls.0.norm.bias', '0.jump.mmb.enc.3.lls.1.conv.weight', '0.jump.mmb.enc.3.lls.1.conv.bias', '0.jump.mmb.enc.3.lls.1.norm.weight', '0.jump.mmb.enc.3.lls.1.norm.bias', '0.jump.mmb.enc.3.lls.2.conv.weight', '0.jump.mmb.enc.3.lls.2.conv.bias', '0.jump.mmb.enc.3.lls.2.norm.weight', '0.jump.mmb.enc.3.lls.2.norm.bias', '0.jump.mmb.enc.3.lls.3.conv.weight', '0.jump.mmb.enc.3.lls.3.conv.bias', '0.jump.mmb.enc.3.lls.3.norm.weight', '0.jump.mmb.enc.3.lls.3.norm.bias', '0.jump.mmb.enc.4.conv1.weight', '0.jump.mmb.enc.4.conv1.bias', '0.jump.mmb.enc.4.lls.0.conv.weight', '0.jump.mmb.enc.4.lls.0.conv.bias', '0.jump.mmb.enc.4.lls.0.norm.weight', '0.jump.mmb.enc.4.lls.0.norm.bias', '0.jump.mmb.enc.4.lls.1.conv.weight', '0.jump.mmb.enc.4.lls.1.conv.bias', '0.jump.mmb.enc.4.lls.1.norm.weight', '0.jump.mmb.enc.4.lls.1.norm.bias', '0.jump.mmb.enc.4.lls.2.conv.weight', '0.jump.mmb.enc.4.lls.2.conv.bias', '0.jump.mmb.enc.4.lls.2.norm.weight', '0.jump.mmb.enc.4.lls.2.norm.bias', '0.jump.mmb.enc.4.lls.3.conv.weight', '0.jump.mmb.enc.4.lls.3.conv.bias', '0.jump.mmb.enc.4.lls.3.norm.weight', '0.jump.mmb.enc.4.lls.3.norm.bias', '0.jump.mmb.enc.5.conv1.weight', '0.jump.mmb.enc.5.conv1.bias', '0.jump.mmb.enc.5.lls.0.conv.weight', '0.jump.mmb.enc.5.lls.0.conv.bias', '0.jump.mmb.enc.5.lls.0.norm.weight', '0.jump.mmb.enc.5.lls.0.norm.bias', '0.jump.mmb.enc.5.lls.1.conv.weight', '0.jump.mmb.enc.5.lls.1.conv.bias', '0.jump.mmb.enc.5.lls.1.norm.weight', '0.jump.mmb.enc.5.lls.1.norm.bias', '0.jump.mmb.enc.5.lls.2.conv.weight', '0.jump.mmb.enc.5.lls.2.conv.bias', '0.jump.mmb.enc.5.lls.2.norm.weight', '0.jump.mmb.enc.5.lls.2.norm.bias', '0.jump.mmb.enc.5.lls.3.conv.weight', '0.jump.mmb.enc.5.lls.3.conv.bias', '0.jump.mmb.enc.5.lls.3.norm.weight', '0.jump.mmb.enc.5.lls.3.norm.bias', '0.jump.mmb.enc.6.conv1.weight', '0.jump.mmb.enc.6.conv1.bias', '0.jump.mmb.enc.6.lls.0.conv.weight', '0.jump.mmb.enc.6.lls.0.conv.bias', '0.jump.mmb.enc.6.lls.0.norm.weight', '0.jump.mmb.enc.6.lls.0.norm.bias', '0.jump.mmb.enc.6.lls.1.conv.weight', '0.jump.mmb.enc.6.lls.1.conv.bias', '0.jump.mmb.enc.6.lls.1.norm.weight', '0.jump.mmb.enc.6.lls.1.norm.bias', '0.jump.mmb.enc.6.lls.2.conv.weight', '0.jump.mmb.enc.6.lls.2.conv.bias', '0.jump.mmb.enc.6.lls.2.norm.weight', '0.jump.mmb.enc.6.lls.2.norm.bias', '0.jump.mmb.enc.6.lls.3.conv.weight', '0.jump.mmb.enc.6.lls.3.conv.bias', '0.jump.mmb.enc.6.lls.3.norm.weight', '0.jump.mmb.enc.6.lls.3.norm.bias', '0.jump.mmb.enc.7.conv1.weight', '0.jump.mmb.enc.7.conv1.bias', '0.jump.mmb.enc.7.lls.0.conv.weight', '0.jump.mmb.enc.7.lls.0.conv.bias', '0.jump.mmb.enc.7.lls.0.norm.weight', '0.jump.mmb.enc.7.lls.0.norm.bias', '0.jump.mmb.enc.7.lls.1.conv.weight', '0.jump.mmb.enc.7.lls.1.conv.bias', '0.jump.mmb.enc.7.lls.1.norm.weight', '0.jump.mmb.enc.7.lls.1.norm.bias', '0.jump.mmb.enc.7.lls.2.conv.weight', '0.jump.mmb.enc.7.lls.2.conv.bias', '0.jump.mmb.enc.7.lls.2.norm.weight', '0.jump.mmb.enc.7.lls.2.norm.bias', '0.jump.mmb.enc.7.lls.3.conv.weight', '0.jump.mmb.enc.7.lls.3.conv.bias', '0.jump.mmb.enc.7.lls.3.norm.weight', '0.jump.mmb.enc.7.lls.3.norm.bias', '0.jump.mmb.dec.0.conv1.weight', '0.jump.mmb.dec.0.conv1.bias', '0.jump.mmb.dec.0.lls.0.conv.weight', '0.jump.mmb.dec.0.lls.0.conv.bias', '0.jump.mmb.dec.0.lls.0.norm.weight', '0.jump.mmb.dec.0.lls.0.norm.bias', '0.jump.mmb.dec.0.lls.1.conv.weight', '0.jump.mmb.dec.0.lls.1.conv.bias', '0.jump.mmb.dec.0.lls.1.norm.weight', '0.jump.mmb.dec.0.lls.1.norm.bias', '0.jump.mmb.dec.0.lls.2.conv.weight', '0.jump.mmb.dec.0.lls.2.conv.bias', '0.jump.mmb.dec.0.lls.2.norm.weight', '0.jump.mmb.dec.0.lls.2.norm.bias', '0.jump.mmb.dec.0.lls.3.conv.weight', '0.jump.mmb.dec.0.lls.3.conv.bias', '0.jump.mmb.dec.0.lls.3.norm.weight', '0.jump.mmb.dec.0.lls.3.norm.bias', '0.jump.mmb.dec.1.conv1.weight', '0.jump.mmb.dec.1.conv1.bias', '0.jump.mmb.dec.1.lls.0.conv.weight', '0.jump.mmb.dec.1.lls.0.conv.bias', '0.jump.mmb.dec.1.lls.0.norm.weight', '0.jump.mmb.dec.1.lls.0.norm.bias', '0.jump.mmb.dec.1.lls.1.conv.weight', '0.jump.mmb.dec.1.lls.1.conv.bias', '0.jump.mmb.dec.1.lls.1.norm.weight', '0.jump.mmb.dec.1.lls.1.norm.bias', '0.jump.mmb.dec.1.lls.2.conv.weight', '0.jump.mmb.dec.1.lls.2.conv.bias', '0.jump.mmb.dec.1.lls.2.norm.weight', '0.jump.mmb.dec.1.lls.2.norm.bias', '0.jump.mmb.dec.1.lls.3.conv.weight', '0.jump.mmb.dec.1.lls.3.conv.bias', '0.jump.mmb.dec.1.lls.3.norm.weight', '0.jump.mmb.dec.1.lls.3.norm.bias', '0.jump.mmb.dec.2.conv1.weight', '0.jump.mmb.dec.2.conv1.bias', '0.jump.mmb.dec.2.lls.0.conv.weight', '0.jump.mmb.dec.2.lls.0.conv.bias', '0.jump.mmb.dec.2.lls.0.norm.weight', '0.jump.mmb.dec.2.lls.0.norm.bias', '0.jump.mmb.dec.2.lls.1.conv.weight', '0.jump.mmb.dec.2.lls.1.conv.bias', '0.jump.mmb.dec.2.lls.1.norm.weight', '0.jump.mmb.dec.2.lls.1.norm.bias', '0.jump.mmb.dec.2.lls.2.conv.weight', '0.jump.mmb.dec.2.lls.2.conv.bias', '0.jump.mmb.dec.2.lls.2.norm.weight', '0.jump.mmb.dec.2.lls.2.norm.bias', '0.jump.mmb.dec.2.lls.3.conv.weight', '0.jump.mmb.dec.2.lls.3.conv.bias', '0.jump.mmb.dec.2.lls.3.norm.weight', '0.jump.mmb.dec.2.lls.3.norm.bias', '0.jump.mmb.dec.3.conv1.weight', '0.jump.mmb.dec.3.conv1.bias', '0.jump.mmb.dec.3.lls.0.conv.weight', '0.jump.mmb.dec.3.lls.0.conv.bias', '0.jump.mmb.dec.3.lls.0.norm.weight', '0.jump.mmb.dec.3.lls.0.norm.bias', '0.jump.mmb.dec.3.lls.1.conv.weight', '0.jump.mmb.dec.3.lls.1.conv.bias', '0.jump.mmb.dec.3.lls.1.norm.weight', '0.jump.mmb.dec.3.lls.1.norm.bias', '0.jump.mmb.dec.3.lls.2.conv.weight', '0.jump.mmb.dec.3.lls.2.conv.bias', '0.jump.mmb.dec.3.lls.2.norm.weight', '0.jump.mmb.dec.3.lls.2.norm.bias', '0.jump.mmb.dec.3.lls.3.conv.weight', '0.jump.mmb.dec.3.lls.3.conv.bias', '0.jump.mmb.dec.3.lls.3.norm.weight', '0.jump.mmb.dec.3.lls.3.norm.bias', '0.jump.mmb.dec.4.conv1.weight', '0.jump.mmb.dec.4.conv1.bias', '0.jump.mmb.dec.4.lls.0.conv.weight', '0.jump.mmb.dec.4.lls.0.conv.bias', '0.jump.mmb.dec.4.lls.0.norm.weight', '0.jump.mmb.dec.4.lls.0.norm.bias', '0.jump.mmb.dec.4.lls.1.conv.weight', '0.jump.mmb.dec.4.lls.1.conv.bias', '0.jump.mmb.dec.4.lls.1.norm.weight', '0.jump.mmb.dec.4.lls.1.norm.bias', '0.jump.mmb.dec.4.lls.2.conv.weight', '0.jump.mmb.dec.4.lls.2.conv.bias', '0.jump.mmb.dec.4.lls.2.norm.weight', '0.jump.mmb.dec.4.lls.2.norm.bias', '0.jump.mmb.dec.4.lls.3.conv.weight', '0.jump.mmb.dec.4.lls.3.conv.bias', '0.jump.mmb.dec.4.lls.3.norm.weight', '0.jump.mmb.dec.4.lls.3.norm.bias', '0.jump.mmb.dec.5.conv1.weight', '0.jump.mmb.dec.5.conv1.bias', '0.jump.mmb.dec.5.lls.0.conv.weight', '0.jump.mmb.dec.5.lls.0.conv.bias', '0.jump.mmb.dec.5.lls.0.norm.weight', '0.jump.mmb.dec.5.lls.0.norm.bias', '0.jump.mmb.dec.5.lls.1.conv.weight', '0.jump.mmb.dec.5.lls.1.conv.bias', '0.jump.mmb.dec.5.lls.1.norm.weight', '0.jump.mmb.dec.5.lls.1.norm.bias', '0.jump.mmb.dec.5.lls.2.conv.weight', '0.jump.mmb.dec.5.lls.2.conv.bias', '0.jump.mmb.dec.5.lls.2.norm.weight', '0.jump.mmb.dec.5.lls.2.norm.bias', '0.jump.mmb.dec.5.lls.3.conv.weight', '0.jump.mmb.dec.5.lls.3.conv.bias', '0.jump.mmb.dec.5.lls.3.norm.weight', '0.jump.mmb.dec.5.lls.3.norm.bias', '0.jump.mmb.dec.6.conv1.weight', '0.jump.mmb.dec.6.conv1.bias', '0.jump.mmb.dec.6.lls.0.conv.weight', '0.jump.mmb.dec.6.lls.0.conv.bias', '0.jump.mmb.dec.6.lls.0.norm.weight', '0.jump.mmb.dec.6.lls.0.norm.bias', '0.jump.mmb.dec.6.lls.1.conv.weight', '0.jump.mmb.dec.6.lls.1.conv.bias', '0.jump.mmb.dec.6.lls.1.norm.weight', '0.jump.mmb.dec.6.lls.1.norm.bias', '0.jump.mmb.dec.6.lls.2.conv.weight', '0.jump.mmb.dec.6.lls.2.conv.bias', '0.jump.mmb.dec.6.lls.2.norm.weight', '0.jump.mmb.dec.6.lls.2.norm.bias', '0.jump.mmb.dec.6.lls.3.conv.weight', '0.jump.mmb.dec.6.lls.3.conv.bias', '0.jump.mmb.dec.6.lls.3.norm.weight', '0.jump.mmb.dec.6.lls.3.norm.bias', '0.jump.mmb.dec.7.conv1.weight', '0.jump.mmb.dec.7.conv1.bias', '0.jump.mmb.dec.7.lls.0.conv.weight', '0.jump.mmb.dec.7.lls.0.conv.bias', '0.jump.mmb.dec.7.lls.0.norm.weight', '0.jump.mmb.dec.7.lls.0.norm.bias', '0.jump.mmb.dec.7.lls.1.conv.weight', '0.jump.mmb.dec.7.lls.1.conv.bias', '0.jump.mmb.dec.7.lls.1.norm.weight', '0.jump.mmb.dec.7.lls.1.norm.bias', '0.jump.mmb.dec.7.lls.2.conv.weight', '0.jump.mmb.dec.7.lls.2.conv.bias', '0.jump.mmb.dec.7.lls.2.norm.weight', '0.jump.mmb.dec.7.lls.2.norm.bias', '0.jump.mmb.dec.7.lls.3.conv.weight', '0.jump.mmb.dec.7.lls.3.conv.bias', '0.jump.mmb.dec.7.lls.3.norm.weight', '0.jump.mmb.dec.7.lls.3.norm.bias', '0.jump.mapsback.dec.0.conv.conv.weight', '0.jump.mapsback.dec.0.conv.conv.bias', '0.jump.mapsback.dec.0.conv.norm.weight', '0.jump.mapsback.dec.0.conv.norm.bias', '0.jump.mapsback.dec.1.conv.conv.weight', '0.jump.mapsback.dec.1.conv.conv.bias', '0.jump.mapsback.dec.1.conv.norm.weight', '0.jump.mapsback.dec.1.conv.norm.bias', '0.jump.mapsback.dec.2.conv.conv.weight', '0.jump.mapsback.dec.2.conv.conv.bias', '0.jump.mapsback.dec.2.conv.norm.weight', '0.jump.mapsback.dec.2.conv.norm.bias', '0.jump.mapsback.dec.3.conv.conv.weight', '0.jump.mapsback.dec.3.conv.conv.bias', '0.jump.mapsback.dec.3.conv.norm.weight', '0.jump.mapsback.dec.3.conv.norm.bias', '0.jump.mapsback.readout.weight', '0.jump.mapsback.readout.bias', '0.space.NN.upconv.weight', '0.space.NN.upconv.bias', '0.space.NO.pos_embed', '0.space.NO.patch_embed.projection.weight', '0.space.NO.patch_embed.projection.bias', '0.space.NO.blks.0.normlayer1.weight', '0.space.NO.blks.0.normlayer1.bias', '0.space.NO.blks.0.filter.w1', '0.space.NO.blks.0.filter.b1', '0.space.NO.blks.0.filter.w2', '0.space.NO.blks.0.filter.b2', '0.space.NO.blks.0.filter.bias.weight', '0.space.NO.blks.0.filter.bias.bias', '0.space.NO.blks.0.attn.multihead_attn.in_proj_weight', '0.space.NO.blks.0.attn.multihead_attn.in_proj_bias', '0.space.NO.blks.0.attn.multihead_attn.out_proj.weight', '0.space.NO.blks.0.attn.multihead_attn.out_proj.bias', '0.space.NO.blks.0.normlayer2.weight', '0.space.NO.blks.0.normlayer2.bias', '0.space.NO.blks.0.mlp.fc1.weight', '0.space.NO.blks.0.mlp.fc1.bias', '0.space.NO.blks.0.mlp.fc2.weight', '0.space.NO.blks.0.mlp.fc2.bias', '0.space.NO.blks.1.normlayer1.weight', '0.space.NO.blks.1.normlayer1.bias', '0.space.NO.blks.1.filter.w1', '0.space.NO.blks.1.filter.b1', '0.space.NO.blks.1.filter.w2', '0.space.NO.blks.1.filter.b2', '0.space.NO.blks.1.filter.bias.weight', '0.space.NO.blks.1.filter.bias.bias', '0.space.NO.blks.1.attn.multihead_attn.in_proj_weight', '0.space.NO.blks.1.attn.multihead_attn.in_proj_bias', '0.space.NO.blks.1.attn.multihead_attn.out_proj.weight', '0.space.NO.blks.1.attn.multihead_attn.out_proj.bias', '0.space.NO.blks.1.normlayer2.weight', '0.space.NO.blks.1.normlayer2.bias', '0.space.NO.blks.1.mlp.fc1.weight', '0.space.NO.blks.1.mlp.fc1.bias', '0.space.NO.blks.1.mlp.fc2.weight', '0.space.NO.blks.1.mlp.fc2.bias', '0.space.NO.blks.2.normlayer1.weight', '0.space.NO.blks.2.normlayer1.bias', '0.space.NO.blks.2.filter.w1', '0.space.NO.blks.2.filter.b1', '0.space.NO.blks.2.filter.w2', '0.space.NO.blks.2.filter.b2', '0.space.NO.blks.2.filter.bias.weight', '0.space.NO.blks.2.filter.bias.bias', '0.space.NO.blks.2.attn.multihead_attn.in_proj_weight', '0.space.NO.blks.2.attn.multihead_attn.in_proj_bias', '0.space.NO.blks.2.attn.multihead_attn.out_proj.weight', '0.space.NO.blks.2.attn.multihead_attn.out_proj.bias', '0.space.NO.blks.2.normlayer2.weight', '0.space.NO.blks.2.normlayer2.bias', '0.space.NO.blks.2.mlp.fc1.weight', '0.space.NO.blks.2.mlp.fc1.bias', '0.space.NO.blks.2.mlp.fc2.weight', '0.space.NO.blks.2.mlp.fc2.bias', '0.space.NO.blks.3.normlayer1.weight', '0.space.NO.blks.3.normlayer1.bias', '0.space.NO.blks.3.filter.w1', '0.space.NO.blks.3.filter.b1', '0.space.NO.blks.3.filter.w2', '0.space.NO.blks.3.filter.b2', '0.space.NO.blks.3.filter.bias.weight', '0.space.NO.blks.3.filter.bias.bias', '0.space.NO.blks.3.attn.multihead_attn.in_proj_weight', '0.space.NO.blks.3.attn.multihead_attn.in_proj_bias', '0.space.NO.blks.3.attn.multihead_attn.out_proj.weight', '0.space.NO.blks.3.attn.multihead_attn.out_proj.bias', '0.space.NO.blks.3.normlayer2.weight', '0.space.NO.blks.3.normlayer2.bias', '0.space.NO.blks.3.mlp.fc1.weight', '0.space.NO.blks.3.mlp.fc1.bias', '0.space.NO.blks.3.mlp.fc2.weight', '0.space.NO.blks.3.mlp.fc2.bias', '0.space.NO.blks.4.normlayer1.weight', '0.space.NO.blks.4.normlayer1.bias', '0.space.NO.blks.4.filter.w1', '0.space.NO.blks.4.filter.b1', '0.space.NO.blks.4.filter.w2', '0.space.NO.blks.4.filter.b2', '0.space.NO.blks.4.filter.bias.weight', '0.space.NO.blks.4.filter.bias.bias', '0.space.NO.blks.4.attn.multihead_attn.in_proj_weight', '0.space.NO.blks.4.attn.multihead_attn.in_proj_bias', '0.space.NO.blks.4.attn.multihead_attn.out_proj.weight', '0.space.NO.blks.4.attn.multihead_attn.out_proj.bias', '0.space.NO.blks.4.normlayer2.weight', '0.space.NO.blks.4.normlayer2.bias', '0.space.NO.blks.4.mlp.fc1.weight', '0.space.NO.blks.4.mlp.fc1.bias', '0.space.NO.blks.4.mlp.fc2.weight', '0.space.NO.blks.4.mlp.fc2.bias', '0.space.NO.blks.5.normlayer1.weight', '0.space.NO.blks.5.normlayer1.bias', '0.space.NO.blks.5.filter.w1', '0.space.NO.blks.5.filter.b1', '0.space.NO.blks.5.filter.w2', '0.space.NO.blks.5.filter.b2', '0.space.NO.blks.5.filter.bias.weight', '0.space.NO.blks.5.filter.bias.bias', '0.space.NO.blks.5.attn.multihead_attn.in_proj_weight', '0.space.NO.blks.5.attn.multihead_attn.in_proj_bias', '0.space.NO.blks.5.attn.multihead_attn.out_proj.weight', '0.space.NO.blks.5.attn.multihead_attn.out_proj.bias', '0.space.NO.blks.5.normlayer2.weight', '0.space.NO.blks.5.normlayer2.bias', '0.space.NO.blks.5.mlp.fc1.weight', '0.space.NO.blks.5.mlp.fc1.bias', '0.space.NO.blks.5.mlp.fc2.weight', '0.space.NO.blks.5.mlp.fc2.bias', '0.space.NO.blks.6.normlayer1.weight', '0.space.NO.blks.6.normlayer1.bias', '0.space.NO.blks.6.filter.w1', '0.space.NO.blks.6.filter.b1', '0.space.NO.blks.6.filter.w2', '0.space.NO.blks.6.filter.b2', '0.space.NO.blks.6.filter.bias.weight', '0.space.NO.blks.6.filter.bias.bias', '0.space.NO.blks.6.attn.multihead_attn.in_proj_weight', '0.space.NO.blks.6.attn.multihead_attn.in_proj_bias', '0.space.NO.blks.6.attn.multihead_attn.out_proj.weight', '0.space.NO.blks.6.attn.multihead_attn.out_proj.bias', '0.space.NO.blks.6.normlayer2.weight', '0.space.NO.blks.6.normlayer2.bias', '0.space.NO.blks.6.mlp.fc1.weight', '0.space.NO.blks.6.mlp.fc1.bias', '0.space.NO.blks.6.mlp.fc2.weight', '0.space.NO.blks.6.mlp.fc2.bias', '0.space.NO.blks.7.normlayer1.weight', '0.space.NO.blks.7.normlayer1.bias', '0.space.NO.blks.7.filter.w1', '0.space.NO.blks.7.filter.b1', '0.space.NO.blks.7.filter.w2', '0.space.NO.blks.7.filter.b2', '0.space.NO.blks.7.filter.bias.weight', '0.space.NO.blks.7.filter.bias.bias', '0.space.NO.blks.7.attn.multihead_attn.in_proj_weight', '0.space.NO.blks.7.attn.multihead_attn.in_proj_bias', '0.space.NO.blks.7.attn.multihead_attn.out_proj.weight', '0.space.NO.blks.7.attn.multihead_attn.out_proj.bias', '0.space.NO.blks.7.normlayer2.weight', '0.space.NO.blks.7.normlayer2.bias', '0.space.NO.blks.7.mlp.fc1.weight', '0.space.NO.blks.7.mlp.fc1.bias', '0.space.NO.blks.7.mlp.fc2.weight', '0.space.NO.blks.7.mlp.fc2.bias', '0.space.NO.blks.8.normlayer1.weight', '0.space.NO.blks.8.normlayer1.bias', '0.space.NO.blks.8.filter.w1', '0.space.NO.blks.8.filter.b1', '0.space.NO.blks.8.filter.w2', '0.space.NO.blks.8.filter.b2', '0.space.NO.blks.8.filter.bias.weight', '0.space.NO.blks.8.filter.bias.bias', '0.space.NO.blks.8.attn.multihead_attn.in_proj_weight', '0.space.NO.blks.8.attn.multihead_attn.in_proj_bias', '0.space.NO.blks.8.attn.multihead_attn.out_proj.weight', '0.space.NO.blks.8.attn.multihead_attn.out_proj.bias', '0.space.NO.blks.8.normlayer2.weight', '0.space.NO.blks.8.normlayer2.bias', '0.space.NO.blks.8.mlp.fc1.weight', '0.space.NO.blks.8.mlp.fc1.bias', '0.space.NO.blks.8.mlp.fc2.weight', '0.space.NO.blks.8.mlp.fc2.bias', '0.space.NO.blks.9.normlayer1.weight', '0.space.NO.blks.9.normlayer1.bias', '0.space.NO.blks.9.filter.w1', '0.space.NO.blks.9.filter.b1', '0.space.NO.blks.9.filter.w2', '0.space.NO.blks.9.filter.b2', '0.space.NO.blks.9.filter.bias.weight', '0.space.NO.blks.9.filter.bias.bias', '0.space.NO.blks.9.attn.multihead_attn.in_proj_weight', '0.space.NO.blks.9.attn.multihead_attn.in_proj_bias', '0.space.NO.blks.9.attn.multihead_attn.out_proj.weight', '0.space.NO.blks.9.attn.multihead_attn.out_proj.bias', '0.space.NO.blks.9.normlayer2.weight', '0.space.NO.blks.9.normlayer2.bias', '0.space.NO.blks.9.mlp.fc1.weight', '0.space.NO.blks.9.mlp.fc1.bias', '0.space.NO.blks.9.mlp.fc2.weight', '0.space.NO.blks.9.mlp.fc2.bias', '0.space.NO.blks.10.normlayer1.weight', '0.space.NO.blks.10.normlayer1.bias', '0.space.NO.blks.10.filter.w1', '0.space.NO.blks.10.filter.b1', '0.space.NO.blks.10.filter.w2', '0.space.NO.blks.10.filter.b2', '0.space.NO.blks.10.filter.bias.weight', '0.space.NO.blks.10.filter.bias.bias', '0.space.NO.blks.10.attn.multihead_attn.in_proj_weight', '0.space.NO.blks.10.attn.multihead_attn.in_proj_bias', '0.space.NO.blks.10.attn.multihead_attn.out_proj.weight', '0.space.NO.blks.10.attn.multihead_attn.out_proj.bias', '0.space.NO.blks.10.normlayer2.weight', '0.space.NO.blks.10.normlayer2.bias', '0.space.NO.blks.10.mlp.fc1.weight', '0.space.NO.blks.10.mlp.fc1.bias', '0.space.NO.blks.10.mlp.fc2.weight', '0.space.NO.blks.10.mlp.fc2.bias', '0.space.NO.blks.11.normlayer1.weight', '0.space.NO.blks.11.normlayer1.bias', '0.space.NO.blks.11.filter.w1', '0.space.NO.blks.11.filter.b1', '0.space.NO.blks.11.filter.w2', '0.space.NO.blks.11.filter.b2', '0.space.NO.blks.11.filter.bias.weight', '0.space.NO.blks.11.filter.bias.bias', '0.space.NO.blks.11.attn.multihead_attn.in_proj_weight', '0.space.NO.blks.11.attn.multihead_attn.in_proj_bias', '0.space.NO.blks.11.attn.multihead_attn.out_proj.weight', '0.space.NO.blks.11.attn.multihead_attn.out_proj.bias', '0.space.NO.blks.11.normlayer2.weight', '0.space.NO.blks.11.normlayer2.bias', '0.space.NO.blks.11.mlp.fc1.weight', '0.space.NO.blks.11.mlp.fc1.bias', '0.space.NO.blks.11.mlp.fc2.weight', '0.space.NO.blks.11.mlp.fc2.bias', '0.space.NO.norm.weight', '0.space.NO.norm.bias', '0.space.NO.lproj.transposeconv1.weight', '0.space.NO.lproj.transposeconv1.bias', '0.space.NO.lproj.transposeconv2.weight', '0.space.NO.lproj.transposeconv2.bias', '0.space.NO.lproj.transposeconv3.weight', '0.space.NO.lproj.transposeconv3.bias', '0.space.up.weight', '0.space.up.bias', '0.space.down.weight', '0.space.down.bias', '0.space.conv1x1.weight', '0.space.conv1x1.bias', '0.maps.enc.0.conv.conv.weight', '0.maps.enc.0.conv.conv.bias', '0.maps.enc.0.conv.norm.weight', '0.maps.enc.0.conv.norm.bias', '0.maps.enc.1.conv.conv.weight', '0.maps.enc.1.conv.conv.bias', '0.maps.enc.1.conv.norm.weight', '0.maps.enc.1.conv.norm.bias', '0.dynamics.norm.weight', '0.dynamics.norm.bias', '0.dynamics.enc.0.conv1.weight', '0.dynamics.enc.0.conv1.bias', '0.dynamics.enc.0.lls.0.conv.weight', '0.dynamics.enc.0.lls.0.conv.bias', '0.dynamics.enc.0.lls.0.norm.weight', '0.dynamics.enc.0.lls.0.norm.bias', '0.dynamics.enc.0.lls.1.conv.weight', '0.dynamics.enc.0.lls.1.conv.bias', '0.dynamics.enc.0.lls.1.norm.weight', '0.dynamics.enc.0.lls.1.norm.bias', '0.dynamics.enc.0.lls.2.conv.weight', '0.dynamics.enc.0.lls.2.conv.bias', '0.dynamics.enc.0.lls.2.norm.weight', '0.dynamics.enc.0.lls.2.norm.bias', '0.dynamics.enc.0.lls.3.conv.weight', '0.dynamics.enc.0.lls.3.conv.bias', '0.dynamics.enc.0.lls.3.norm.weight', '0.dynamics.enc.0.lls.3.norm.bias', '0.dynamics.enc.1.conv1.weight', '0.dynamics.enc.1.conv1.bias', '0.dynamics.enc.1.lls.0.conv.weight', '0.dynamics.enc.1.lls.0.conv.bias', '0.dynamics.enc.1.lls.0.norm.weight', '0.dynamics.enc.1.lls.0.norm.bias', '0.dynamics.enc.1.lls.1.conv.weight', '0.dynamics.enc.1.lls.1.conv.bias', '0.dynamics.enc.1.lls.1.norm.weight', '0.dynamics.enc.1.lls.1.norm.bias', '0.dynamics.enc.1.lls.2.conv.weight', '0.dynamics.enc.1.lls.2.conv.bias', '0.dynamics.enc.1.lls.2.norm.weight', '0.dynamics.enc.1.lls.2.norm.bias', '0.dynamics.enc.1.lls.3.conv.weight', '0.dynamics.enc.1.lls.3.conv.bias', '0.dynamics.enc.1.lls.3.norm.weight', '0.dynamics.enc.1.lls.3.norm.bias', '0.dynamics.enc.2.conv1.weight', '0.dynamics.enc.2.conv1.bias', '0.dynamics.enc.2.lls.0.conv.weight', '0.dynamics.enc.2.lls.0.conv.bias', '0.dynamics.enc.2.lls.0.norm.weight', '0.dynamics.enc.2.lls.0.norm.bias', '0.dynamics.enc.2.lls.1.conv.weight', '0.dynamics.enc.2.lls.1.conv.bias', '0.dynamics.enc.2.lls.1.norm.weight', '0.dynamics.enc.2.lls.1.norm.bias', '0.dynamics.enc.2.lls.2.conv.weight', '0.dynamics.enc.2.lls.2.conv.bias', '0.dynamics.enc.2.lls.2.norm.weight', '0.dynamics.enc.2.lls.2.norm.bias', '0.dynamics.enc.2.lls.3.conv.weight', '0.dynamics.enc.2.lls.3.conv.bias', '0.dynamics.enc.2.lls.3.norm.weight', '0.dynamics.enc.2.lls.3.norm.bias', '0.dynamics.enc.3.conv1.weight', '0.dynamics.enc.3.conv1.bias', '0.dynamics.enc.3.lls.0.conv.weight', '0.dynamics.enc.3.lls.0.conv.bias', '0.dynamics.enc.3.lls.0.norm.weight', '0.dynamics.enc.3.lls.0.norm.bias', '0.dynamics.enc.3.lls.1.conv.weight', '0.dynamics.enc.3.lls.1.conv.bias', '0.dynamics.enc.3.lls.1.norm.weight', '0.dynamics.enc.3.lls.1.norm.bias', '0.dynamics.enc.3.lls.2.conv.weight', '0.dynamics.enc.3.lls.2.conv.bias', '0.dynamics.enc.3.lls.2.norm.weight', '0.dynamics.enc.3.lls.2.norm.bias', '0.dynamics.enc.3.lls.3.conv.weight', '0.dynamics.enc.3.lls.3.conv.bias', '0.dynamics.enc.3.lls.3.norm.weight', '0.dynamics.enc.3.lls.3.norm.bias', '0.dynamics.enc.4.conv1.weight', '0.dynamics.enc.4.conv1.bias', '0.dynamics.enc.4.lls.0.conv.weight', '0.dynamics.enc.4.lls.0.conv.bias', '0.dynamics.enc.4.lls.0.norm.weight', '0.dynamics.enc.4.lls.0.norm.bias', '0.dynamics.enc.4.lls.1.conv.weight', '0.dynamics.enc.4.lls.1.conv.bias', '0.dynamics.enc.4.lls.1.norm.weight', '0.dynamics.enc.4.lls.1.norm.bias', '0.dynamics.enc.4.lls.2.conv.weight', '0.dynamics.enc.4.lls.2.conv.bias', '0.dynamics.enc.4.lls.2.norm.weight', '0.dynamics.enc.4.lls.2.norm.bias', '0.dynamics.enc.4.lls.3.conv.weight', '0.dynamics.enc.4.lls.3.conv.bias', '0.dynamics.enc.4.lls.3.norm.weight', '0.dynamics.enc.4.lls.3.norm.bias', '0.dynamics.enc.5.conv1.weight', '0.dynamics.enc.5.conv1.bias', '0.dynamics.enc.5.lls.0.conv.weight', '0.dynamics.enc.5.lls.0.conv.bias', '0.dynamics.enc.5.lls.0.norm.weight', '0.dynamics.enc.5.lls.0.norm.bias', '0.dynamics.enc.5.lls.1.conv.weight', '0.dynamics.enc.5.lls.1.conv.bias', '0.dynamics.enc.5.lls.1.norm.weight', '0.dynamics.enc.5.lls.1.norm.bias', '0.dynamics.enc.5.lls.2.conv.weight', '0.dynamics.enc.5.lls.2.conv.bias', '0.dynamics.enc.5.lls.2.norm.weight', '0.dynamics.enc.5.lls.2.norm.bias', '0.dynamics.enc.5.lls.3.conv.weight', '0.dynamics.enc.5.lls.3.conv.bias', '0.dynamics.enc.5.lls.3.norm.weight', '0.dynamics.enc.5.lls.3.norm.bias', '0.dynamics.enc.6.conv1.weight', '0.dynamics.enc.6.conv1.bias', '0.dynamics.enc.6.lls.0.conv.weight', '0.dynamics.enc.6.lls.0.conv.bias', '0.dynamics.enc.6.lls.0.norm.weight', '0.dynamics.enc.6.lls.0.norm.bias', '0.dynamics.enc.6.lls.1.conv.weight', '0.dynamics.enc.6.lls.1.conv.bias', '0.dynamics.enc.6.lls.1.norm.weight', '0.dynamics.enc.6.lls.1.norm.bias', '0.dynamics.enc.6.lls.2.conv.weight', '0.dynamics.enc.6.lls.2.conv.bias', '0.dynamics.enc.6.lls.2.norm.weight', '0.dynamics.enc.6.lls.2.norm.bias', '0.dynamics.enc.6.lls.3.conv.weight', '0.dynamics.enc.6.lls.3.conv.bias', '0.dynamics.enc.6.lls.3.norm.weight', '0.dynamics.enc.6.lls.3.norm.bias', '0.dynamics.enc.7.conv1.weight', '0.dynamics.enc.7.conv1.bias', '0.dynamics.enc.7.lls.0.conv.weight', '0.dynamics.enc.7.lls.0.conv.bias', '0.dynamics.enc.7.lls.0.norm.weight', '0.dynamics.enc.7.lls.0.norm.bias', '0.dynamics.enc.7.lls.1.conv.weight', '0.dynamics.enc.7.lls.1.conv.bias', '0.dynamics.enc.7.lls.1.norm.weight', '0.dynamics.enc.7.lls.1.norm.bias', '0.dynamics.enc.7.lls.2.conv.weight', '0.dynamics.enc.7.lls.2.conv.bias', '0.dynamics.enc.7.lls.2.norm.weight', '0.dynamics.enc.7.lls.2.norm.bias', '0.dynamics.enc.7.lls.3.conv.weight', '0.dynamics.enc.7.lls.3.conv.bias', '0.dynamics.enc.7.lls.3.norm.weight', '0.dynamics.enc.7.lls.3.norm.bias', '0.dynamics.blocks.0.normlayer1.weight', '0.dynamics.blocks.0.normlayer1.bias', '0.dynamics.blocks.0.filter.w1', '0.dynamics.blocks.0.filter.b1', '0.dynamics.blocks.0.filter.w2', '0.dynamics.blocks.0.filter.b2', '0.dynamics.blocks.0.filter.bias.weight', '0.dynamics.blocks.0.filter.bias.bias', '0.dynamics.blocks.0.normlayer2.weight', '0.dynamics.blocks.0.normlayer2.bias', '0.dynamics.blocks.0.mlp.fc1.weight', '0.dynamics.blocks.0.mlp.fc1.bias', '0.dynamics.blocks.0.mlp.fc2.weight', '0.dynamics.blocks.0.mlp.fc2.bias', '0.dynamics.blocks.1.normlayer1.weight', '0.dynamics.blocks.1.normlayer1.bias', '0.dynamics.blocks.1.filter.w1', '0.dynamics.blocks.1.filter.b1', '0.dynamics.blocks.1.filter.w2', '0.dynamics.blocks.1.filter.b2', '0.dynamics.blocks.1.filter.bias.weight', '0.dynamics.blocks.1.filter.bias.bias', '0.dynamics.blocks.1.normlayer2.weight', '0.dynamics.blocks.1.normlayer2.bias', '0.dynamics.blocks.1.mlp.fc1.weight', '0.dynamics.blocks.1.mlp.fc1.bias', '0.dynamics.blocks.1.mlp.fc2.weight', '0.dynamics.blocks.1.mlp.fc2.bias', '0.dynamics.blocks.2.normlayer1.weight', '0.dynamics.blocks.2.normlayer1.bias', '0.dynamics.blocks.2.filter.w1', '0.dynamics.blocks.2.filter.b1', '0.dynamics.blocks.2.filter.w2', '0.dynamics.blocks.2.filter.b2', '0.dynamics.blocks.2.filter.bias.weight', '0.dynamics.blocks.2.filter.bias.bias', '0.dynamics.blocks.2.normlayer2.weight', '0.dynamics.blocks.2.normlayer2.bias', '0.dynamics.blocks.2.mlp.fc1.weight', '0.dynamics.blocks.2.mlp.fc1.bias', '0.dynamics.blocks.2.mlp.fc2.weight', '0.dynamics.blocks.2.mlp.fc2.bias', '0.dynamics.blocks.3.normlayer1.weight', '0.dynamics.blocks.3.normlayer1.bias', '0.dynamics.blocks.3.filter.w1', '0.dynamics.blocks.3.filter.b1', '0.dynamics.blocks.3.filter.w2', '0.dynamics.blocks.3.filter.b2', '0.dynamics.blocks.3.filter.bias.weight', '0.dynamics.blocks.3.filter.bias.bias', '0.dynamics.blocks.3.normlayer2.weight', '0.dynamics.blocks.3.normlayer2.bias', '0.dynamics.blocks.3.mlp.fc1.weight', '0.dynamics.blocks.3.mlp.fc1.bias', '0.dynamics.blocks.3.mlp.fc2.weight', '0.dynamics.blocks.3.mlp.fc2.bias', '0.dynamics.blocks.4.normlayer1.weight', '0.dynamics.blocks.4.normlayer1.bias', '0.dynamics.blocks.4.filter.w1', '0.dynamics.blocks.4.filter.b1', '0.dynamics.blocks.4.filter.w2', '0.dynamics.blocks.4.filter.b2', '0.dynamics.blocks.4.filter.bias.weight', '0.dynamics.blocks.4.filter.bias.bias', '0.dynamics.blocks.4.normlayer2.weight', '0.dynamics.blocks.4.normlayer2.bias', '0.dynamics.blocks.4.mlp.fc1.weight', '0.dynamics.blocks.4.mlp.fc1.bias', '0.dynamics.blocks.4.mlp.fc2.weight', '0.dynamics.blocks.4.mlp.fc2.bias', '0.dynamics.blocks.5.normlayer1.weight', '0.dynamics.blocks.5.normlayer1.bias', '0.dynamics.blocks.5.filter.w1', '0.dynamics.blocks.5.filter.b1', '0.dynamics.blocks.5.filter.w2', '0.dynamics.blocks.5.filter.b2', '0.dynamics.blocks.5.filter.bias.weight', '0.dynamics.blocks.5.filter.bias.bias', '0.dynamics.blocks.5.normlayer2.weight', '0.dynamics.blocks.5.normlayer2.bias', '0.dynamics.blocks.5.mlp.fc1.weight', '0.dynamics.blocks.5.mlp.fc1.bias', '0.dynamics.blocks.5.mlp.fc2.weight', '0.dynamics.blocks.5.mlp.fc2.bias', '0.dynamics.blocks.6.normlayer1.weight', '0.dynamics.blocks.6.normlayer1.bias', '0.dynamics.blocks.6.filter.w1', '0.dynamics.blocks.6.filter.b1', '0.dynamics.blocks.6.filter.w2', '0.dynamics.blocks.6.filter.b2', '0.dynamics.blocks.6.filter.bias.weight', '0.dynamics.blocks.6.filter.bias.bias', '0.dynamics.blocks.6.normlayer2.weight', '0.dynamics.blocks.6.normlayer2.bias', '0.dynamics.blocks.6.mlp.fc1.weight', '0.dynamics.blocks.6.mlp.fc1.bias', '0.dynamics.blocks.6.mlp.fc2.weight', '0.dynamics.blocks.6.mlp.fc2.bias', '0.dynamics.blocks.7.normlayer1.weight', '0.dynamics.blocks.7.normlayer1.bias', '0.dynamics.blocks.7.filter.w1', '0.dynamics.blocks.7.filter.b1', '0.dynamics.blocks.7.filter.w2', '0.dynamics.blocks.7.filter.b2', '0.dynamics.blocks.7.filter.bias.weight', '0.dynamics.blocks.7.filter.bias.bias', '0.dynamics.blocks.7.normlayer2.weight', '0.dynamics.blocks.7.normlayer2.bias', '0.dynamics.blocks.7.mlp.fc1.weight', '0.dynamics.blocks.7.mlp.fc1.bias', '0.dynamics.blocks.7.mlp.fc2.weight', '0.dynamics.blocks.7.mlp.fc2.bias', '0.dynamics.blocks.8.normlayer1.weight', '0.dynamics.blocks.8.normlayer1.bias', '0.dynamics.blocks.8.filter.w1', '0.dynamics.blocks.8.filter.b1', '0.dynamics.blocks.8.filter.w2', '0.dynamics.blocks.8.filter.b2', '0.dynamics.blocks.8.filter.bias.weight', '0.dynamics.blocks.8.filter.bias.bias', '0.dynamics.blocks.8.normlayer2.weight', '0.dynamics.blocks.8.normlayer2.bias', '0.dynamics.blocks.8.mlp.fc1.weight', '0.dynamics.blocks.8.mlp.fc1.bias', '0.dynamics.blocks.8.mlp.fc2.weight', '0.dynamics.blocks.8.mlp.fc2.bias', '0.dynamics.blocks.9.normlayer1.weight', '0.dynamics.blocks.9.normlayer1.bias', '0.dynamics.blocks.9.filter.w1', '0.dynamics.blocks.9.filter.b1', '0.dynamics.blocks.9.filter.w2', '0.dynamics.blocks.9.filter.b2', '0.dynamics.blocks.9.filter.bias.weight', '0.dynamics.blocks.9.filter.bias.bias', '0.dynamics.blocks.9.normlayer2.weight', '0.dynamics.blocks.9.normlayer2.bias', '0.dynamics.blocks.9.mlp.fc1.weight', '0.dynamics.blocks.9.mlp.fc1.bias', '0.dynamics.blocks.9.mlp.fc2.weight', '0.dynamics.blocks.9.mlp.fc2.bias', '0.dynamics.blocks.10.normlayer1.weight', '0.dynamics.blocks.10.normlayer1.bias', '0.dynamics.blocks.10.filter.w1', '0.dynamics.blocks.10.filter.b1', '0.dynamics.blocks.10.filter.w2', '0.dynamics.blocks.10.filter.b2', '0.dynamics.blocks.10.filter.bias.weight', '0.dynamics.blocks.10.filter.bias.bias', '0.dynamics.blocks.10.normlayer2.weight', '0.dynamics.blocks.10.normlayer2.bias', '0.dynamics.blocks.10.mlp.fc1.weight', '0.dynamics.blocks.10.mlp.fc1.bias', '0.dynamics.blocks.10.mlp.fc2.weight', '0.dynamics.blocks.10.mlp.fc2.bias', '0.dynamics.blocks.11.normlayer1.weight', '0.dynamics.blocks.11.normlayer1.bias', '0.dynamics.blocks.11.filter.w1', '0.dynamics.blocks.11.filter.b1', '0.dynamics.blocks.11.filter.w2', '0.dynamics.blocks.11.filter.b2', '0.dynamics.blocks.11.filter.bias.weight', '0.dynamics.blocks.11.filter.bias.bias', '0.dynamics.blocks.11.normlayer2.weight', '0.dynamics.blocks.11.normlayer2.bias', '0.dynamics.blocks.11.mlp.fc1.weight', '0.dynamics.blocks.11.mlp.fc1.bias', '0.dynamics.blocks.11.mlp.fc2.weight', '0.dynamics.blocks.11.mlp.fc2.bias', '0.dynamics.dec.0.conv1.weight', '0.dynamics.dec.0.conv1.bias', '0.dynamics.dec.0.lls.0.conv.weight', '0.dynamics.dec.0.lls.0.conv.bias', '0.dynamics.dec.0.lls.0.norm.weight', '0.dynamics.dec.0.lls.0.norm.bias', '0.dynamics.dec.0.lls.1.conv.weight', '0.dynamics.dec.0.lls.1.conv.bias', '0.dynamics.dec.0.lls.1.norm.weight', '0.dynamics.dec.0.lls.1.norm.bias', '0.dynamics.dec.0.lls.2.conv.weight', '0.dynamics.dec.0.lls.2.conv.bias', '0.dynamics.dec.0.lls.2.norm.weight', '0.dynamics.dec.0.lls.2.norm.bias', '0.dynamics.dec.0.lls.3.conv.weight', '0.dynamics.dec.0.lls.3.conv.bias', '0.dynamics.dec.0.lls.3.norm.weight', '0.dynamics.dec.0.lls.3.norm.bias', '0.dynamics.dec.1.conv1.weight', '0.dynamics.dec.1.conv1.bias', '0.dynamics.dec.1.lls.0.conv.weight', '0.dynamics.dec.1.lls.0.conv.bias', '0.dynamics.dec.1.lls.0.norm.weight', '0.dynamics.dec.1.lls.0.norm.bias', '0.dynamics.dec.1.lls.1.conv.weight', '0.dynamics.dec.1.lls.1.conv.bias', '0.dynamics.dec.1.lls.1.norm.weight', '0.dynamics.dec.1.lls.1.norm.bias', '0.dynamics.dec.1.lls.2.conv.weight', '0.dynamics.dec.1.lls.2.conv.bias', '0.dynamics.dec.1.lls.2.norm.weight', '0.dynamics.dec.1.lls.2.norm.bias', '0.dynamics.dec.1.lls.3.conv.weight', '0.dynamics.dec.1.lls.3.conv.bias', '0.dynamics.dec.1.lls.3.norm.weight', '0.dynamics.dec.1.lls.3.norm.bias', '0.dynamics.dec.2.conv1.weight', '0.dynamics.dec.2.conv1.bias', '0.dynamics.dec.2.lls.0.conv.weight', '0.dynamics.dec.2.lls.0.conv.bias', '0.dynamics.dec.2.lls.0.norm.weight', '0.dynamics.dec.2.lls.0.norm.bias', '0.dynamics.dec.2.lls.1.conv.weight', '0.dynamics.dec.2.lls.1.conv.bias', '0.dynamics.dec.2.lls.1.norm.weight', '0.dynamics.dec.2.lls.1.norm.bias', '0.dynamics.dec.2.lls.2.conv.weight', '0.dynamics.dec.2.lls.2.conv.bias', '0.dynamics.dec.2.lls.2.norm.weight', '0.dynamics.dec.2.lls.2.norm.bias', '0.dynamics.dec.2.lls.3.conv.weight', '0.dynamics.dec.2.lls.3.conv.bias', '0.dynamics.dec.2.lls.3.norm.weight', '0.dynamics.dec.2.lls.3.norm.bias', '0.dynamics.dec.3.conv1.weight', '0.dynamics.dec.3.conv1.bias', '0.dynamics.dec.3.lls.0.conv.weight', '0.dynamics.dec.3.lls.0.conv.bias', '0.dynamics.dec.3.lls.0.norm.weight', '0.dynamics.dec.3.lls.0.norm.bias', '0.dynamics.dec.3.lls.1.conv.weight', '0.dynamics.dec.3.lls.1.conv.bias', '0.dynamics.dec.3.lls.1.norm.weight', '0.dynamics.dec.3.lls.1.norm.bias', '0.dynamics.dec.3.lls.2.conv.weight', '0.dynamics.dec.3.lls.2.conv.bias', '0.dynamics.dec.3.lls.2.norm.weight', '0.dynamics.dec.3.lls.2.norm.bias', '0.dynamics.dec.3.lls.3.conv.weight', '0.dynamics.dec.3.lls.3.conv.bias', '0.dynamics.dec.3.lls.3.norm.weight', '0.dynamics.dec.3.lls.3.norm.bias', '0.dynamics.dec.4.conv1.weight', '0.dynamics.dec.4.conv1.bias', '0.dynamics.dec.4.lls.0.conv.weight', '0.dynamics.dec.4.lls.0.conv.bias', '0.dynamics.dec.4.lls.0.norm.weight', '0.dynamics.dec.4.lls.0.norm.bias', '0.dynamics.dec.4.lls.1.conv.weight', '0.dynamics.dec.4.lls.1.conv.bias', '0.dynamics.dec.4.lls.1.norm.weight', '0.dynamics.dec.4.lls.1.norm.bias', '0.dynamics.dec.4.lls.2.conv.weight', '0.dynamics.dec.4.lls.2.conv.bias', '0.dynamics.dec.4.lls.2.norm.weight', '0.dynamics.dec.4.lls.2.norm.bias', '0.dynamics.dec.4.lls.3.conv.weight', '0.dynamics.dec.4.lls.3.conv.bias', '0.dynamics.dec.4.lls.3.norm.weight', '0.dynamics.dec.4.lls.3.norm.bias', '0.dynamics.dec.5.conv1.weight', '0.dynamics.dec.5.conv1.bias', '0.dynamics.dec.5.lls.0.conv.weight', '0.dynamics.dec.5.lls.0.conv.bias', '0.dynamics.dec.5.lls.0.norm.weight', '0.dynamics.dec.5.lls.0.norm.bias', '0.dynamics.dec.5.lls.1.conv.weight', '0.dynamics.dec.5.lls.1.conv.bias', '0.dynamics.dec.5.lls.1.norm.weight', '0.dynamics.dec.5.lls.1.norm.bias', '0.dynamics.dec.5.lls.2.conv.weight', '0.dynamics.dec.5.lls.2.conv.bias', '0.dynamics.dec.5.lls.2.norm.weight', '0.dynamics.dec.5.lls.2.norm.bias', '0.dynamics.dec.5.lls.3.conv.weight', '0.dynamics.dec.5.lls.3.conv.bias', '0.dynamics.dec.5.lls.3.norm.weight', '0.dynamics.dec.5.lls.3.norm.bias', '0.dynamics.dec.6.conv1.weight', '0.dynamics.dec.6.conv1.bias', '0.dynamics.dec.6.lls.0.conv.weight', '0.dynamics.dec.6.lls.0.conv.bias', '0.dynamics.dec.6.lls.0.norm.weight', '0.dynamics.dec.6.lls.0.norm.bias', '0.dynamics.dec.6.lls.1.conv.weight', '0.dynamics.dec.6.lls.1.conv.bias', '0.dynamics.dec.6.lls.1.norm.weight', '0.dynamics.dec.6.lls.1.norm.bias', '0.dynamics.dec.6.lls.2.conv.weight', '0.dynamics.dec.6.lls.2.conv.bias', '0.dynamics.dec.6.lls.2.norm.weight', '0.dynamics.dec.6.lls.2.norm.bias', '0.dynamics.dec.6.lls.3.conv.weight', '0.dynamics.dec.6.lls.3.conv.bias', '0.dynamics.dec.6.lls.3.norm.weight', '0.dynamics.dec.6.lls.3.norm.bias', '0.dynamics.dec.7.conv1.weight', '0.dynamics.dec.7.conv1.bias', '0.dynamics.dec.7.lls.0.conv.weight', '0.dynamics.dec.7.lls.0.conv.bias', '0.dynamics.dec.7.lls.0.norm.weight', '0.dynamics.dec.7.lls.0.norm.bias', '0.dynamics.dec.7.lls.1.conv.weight', '0.dynamics.dec.7.lls.1.conv.bias', '0.dynamics.dec.7.lls.1.norm.weight', '0.dynamics.dec.7.lls.1.norm.bias', '0.dynamics.dec.7.lls.2.conv.weight', '0.dynamics.dec.7.lls.2.conv.bias', '0.dynamics.dec.7.lls.2.norm.weight', '0.dynamics.dec.7.lls.2.norm.bias', '0.dynamics.dec.7.lls.3.conv.weight', '0.dynamics.dec.7.lls.3.conv.bias', '0.dynamics.dec.7.lls.3.norm.weight', '0.dynamics.dec.7.lls.3.norm.bias', '0.mapsback.dec.0.conv.conv.weight', '0.mapsback.dec.0.conv.conv.bias', '0.mapsback.dec.0.conv.norm.weight', '0.mapsback.dec.0.conv.norm.bias', '0.mapsback.dec.1.conv.conv.weight', '0.mapsback.dec.1.conv.conv.bias', '0.mapsback.dec.1.conv.norm.weight', '0.mapsback.dec.1.conv.norm.bias', '0.mapsback.readout.weight', '0.mapsback.readout.bias']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sd = model.state_dict()\n",
    "    missing, unexpected = new_model.load_state_dict(sd, strict=False)\n",
    "    print(\"loaded state_dict -> missing:\", missing, \" unexpected:\", unexpected)\n",
    "except Exception as e:\n",
    "    print(\"model.state_dict() not available:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5a72a",
   "metadata": {},
   "source": [
    "Otherwise: copy named_parameters and named_buffers, or fall back to shape-based mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5d2090a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params copied by name: 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "new_model.to(device)\n",
    "\n",
    "# collect source params/buffers\n",
    "src_params = {n: p for n, p in model.named_parameters()} if hasattr(model, 'named_parameters') else {}\n",
    "src_bufs   = {n: b for n, b in model.named_buffers()}    if hasattr(model, 'named_buffers')    else {}\n",
    "\n",
    "copied = []\n",
    "with torch.no_grad():\n",
    "    for name, tgt in new_model.named_parameters():\n",
    "        src = src_params.get(name)\n",
    "        if src is None:\n",
    "            continue\n",
    "        if tuple(src.shape) == tuple(tgt.shape):\n",
    "            tgt.copy_(src.to(tgt.device).to(tgt.dtype))\n",
    "            copied.append(name)\n",
    "\n",
    "    for name, tgt in new_model.named_buffers():\n",
    "        src = src_bufs.get(name)\n",
    "        if src is None:\n",
    "            continue\n",
    "        if tuple(src.shape) == tuple(tgt.shape):\n",
    "            tgt.copy_(src.to(tgt.device).to(tgt.dtype))\n",
    "\n",
    "print(\"params copied by name:\", len(copied))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd5af0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copied by shape: space.norm.weight <- src_index_568 shape=torch.Size([64])\n",
      "copied by shape: space.norm.bias <- src_index_585 shape=torch.Size([64])\n",
      "copied by shape: space.enc.0.conv1.bias <- src_index_289 shape=torch.Size([32])\n",
      "copied by shape: space.enc.0.lls.0.conv.bias <- src_index_601 shape=torch.Size([64])\n",
      "copied by shape: space.enc.0.lls.0.norm.weight <- src_index_618 shape=torch.Size([64])\n",
      "copied by shape: space.enc.0.lls.0.norm.bias <- src_index_635 shape=torch.Size([64])\n",
      "copied by shape: space.enc.0.lls.1.conv.bias <- src_index_652 shape=torch.Size([64])\n",
      "copied by shape: space.enc.0.lls.1.norm.weight <- src_index_669 shape=torch.Size([64])\n",
      "copied by shape: space.enc.0.lls.1.norm.bias <- src_index_686 shape=torch.Size([64])\n",
      "copied by shape: space.enc.0.lls.2.conv.bias <- src_index_871 shape=torch.Size([64])\n",
      "copied by shape: space.enc.0.lls.2.norm.weight <- src_index_888 shape=torch.Size([64])\n",
      "copied by shape: space.enc.0.lls.2.norm.bias <- src_index_905 shape=torch.Size([64])\n",
      "copied by shape: space.enc.1.conv1.bias <- src_index_289 shape=torch.Size([32])\n",
      "copied by shape: space.enc.1.lls.0.conv.bias <- src_index_921 shape=torch.Size([64])\n",
      "copied by shape: space.enc.1.lls.0.norm.weight <- src_index_938 shape=torch.Size([64])\n",
      "copied by shape: space.enc.1.lls.0.norm.bias <- src_index_955 shape=torch.Size([64])\n",
      "copied by shape: space.enc.1.lls.1.conv.bias <- src_index_972 shape=torch.Size([64])\n",
      "copied by shape: space.enc.1.lls.1.norm.weight <- src_index_989 shape=torch.Size([64])\n",
      "copied by shape: space.enc.2.conv1.bias <- src_index_289 shape=torch.Size([32])\n",
      "copied by shape: space.enc.3.conv1.bias <- src_index_290 shape=torch.Size([32])\n",
      "copied by shape: space.enc.4.conv1.bias <- src_index_290 shape=torch.Size([32])\n",
      "copied by shape: space.enc.5.conv1.bias <- src_index_290 shape=torch.Size([32])\n",
      "copied by shape: space.enc.6.conv1.bias <- src_index_291 shape=torch.Size([32])\n",
      "copied by shape: space.enc.7.conv1.bias <- src_index_291 shape=torch.Size([32])\n",
      "copied by shape: space.blocks.0.mlp.fc1.bias <- src_index_19 shape=torch.Size([256])\n",
      "copied by shape: space.blocks.1.mlp.fc1.bias <- src_index_19 shape=torch.Size([256])\n",
      "copied by shape: space.blocks.2.mlp.fc1.bias <- src_index_19 shape=torch.Size([256])\n",
      "copied by shape: space.blocks.3.mlp.fc1.bias <- src_index_20 shape=torch.Size([256])\n",
      "copied by shape: space.blocks.4.mlp.fc1.bias <- src_index_20 shape=torch.Size([256])\n",
      "copied by shape: space.blocks.5.mlp.fc1.bias <- src_index_20 shape=torch.Size([256])\n",
      "copied by shape: space.blocks.6.mlp.fc1.bias <- src_index_21 shape=torch.Size([256])\n",
      "copied by shape: space.blocks.7.mlp.fc1.bias <- src_index_21 shape=torch.Size([256])\n",
      "copied by shape: space.blocks.8.mlp.fc1.bias <- src_index_21 shape=torch.Size([256])\n",
      "copied by shape: space.blocks.9.mlp.fc1.bias <- src_index_22 shape=torch.Size([256])\n",
      "copied by shape: space.blocks.10.mlp.fc1.bias <- src_index_22 shape=torch.Size([256])\n",
      "copied by shape: space.blocks.11.mlp.fc1.bias <- src_index_22 shape=torch.Size([256])\n",
      "copied by shape: space.dec.0.conv1.bias <- src_index_279 shape=torch.Size([32])\n",
      "copied by shape: space.dec.1.conv1.bias <- src_index_280 shape=torch.Size([32])\n",
      "copied by shape: space.dec.2.conv1.bias <- src_index_280 shape=torch.Size([32])\n",
      "copied by shape: space.dec.3.conv1.bias <- src_index_280 shape=torch.Size([32])\n",
      "copied by shape: space.dec.7.lls.0.conv.bias <- src_index_17 shape=torch.Size([128])\n",
      "copied by shape: space.dec.7.lls.0.norm.weight <- src_index_22 shape=torch.Size([128])\n",
      "copied by shape: space.dec.7.lls.0.norm.bias <- src_index_39 shape=torch.Size([128])\n",
      "copied by shape: space.dec.7.lls.1.conv.bias <- src_index_56 shape=torch.Size([128])\n",
      "copied by shape: space.dec.7.lls.1.norm.weight <- src_index_73 shape=torch.Size([128])\n",
      "copied by shape: space.dec.7.lls.1.norm.bias <- src_index_90 shape=torch.Size([128])\n",
      "copied by shape: space.dec.7.lls.2.conv.bias <- src_index_107 shape=torch.Size([128])\n",
      "copied by shape: space.dec.7.lls.2.norm.weight <- src_index_124 shape=torch.Size([128])\n",
      "copied by shape: space.dec.7.lls.2.norm.bias <- src_index_141 shape=torch.Size([128])\n",
      "copied by shape: dynamics.NN.upconv.weight <- src_index_289 shape=torch.Size([5, 5, 1, 1])\n",
      "copied by shape: dynamics.NN.upconv.bias <- src_index_288 shape=torch.Size([5])\n",
      "copied by shape: dynamics.NO.pos_embed <- src_index_289 shape=torch.Size([1, 3780, 768])\n",
      "copied by shape: dynamics.NO.patch_embed.projection.weight <- src_index_289 shape=torch.Size([768, 5, 16, 16])\n",
      "copied by shape: dynamics.NO.patch_embed.projection.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.0.normlayer1.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.0.normlayer1.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.0.filter.w1 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.0.filter.b1 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.0.filter.w2 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.0.filter.b2 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.0.filter.bias.weight <- src_index_289 shape=torch.Size([768, 768, 1])\n",
      "copied by shape: dynamics.NO.blks.0.filter.bias.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.0.attn.multihead_attn.in_proj_weight <- src_index_289 shape=torch.Size([2304, 768])\n",
      "copied by shape: dynamics.NO.blks.0.attn.multihead_attn.in_proj_bias <- src_index_289 shape=torch.Size([2304])\n",
      "copied by shape: dynamics.NO.blks.0.attn.multihead_attn.out_proj.weight <- src_index_289 shape=torch.Size([768, 768])\n",
      "copied by shape: dynamics.NO.blks.0.attn.multihead_attn.out_proj.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.0.normlayer2.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.0.normlayer2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.0.mlp.fc1.weight <- src_index_289 shape=torch.Size([3072, 768])\n",
      "copied by shape: dynamics.NO.blks.0.mlp.fc1.bias <- src_index_289 shape=torch.Size([3072])\n",
      "copied by shape: dynamics.NO.blks.0.mlp.fc2.weight <- src_index_289 shape=torch.Size([768, 3072])\n",
      "copied by shape: dynamics.NO.blks.0.mlp.fc2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.1.normlayer1.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.1.normlayer1.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.1.filter.w1 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.1.filter.b1 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.1.filter.w2 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.1.filter.b2 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.1.filter.bias.weight <- src_index_289 shape=torch.Size([768, 768, 1])\n",
      "copied by shape: dynamics.NO.blks.1.filter.bias.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.1.attn.multihead_attn.in_proj_weight <- src_index_289 shape=torch.Size([2304, 768])\n",
      "copied by shape: dynamics.NO.blks.1.attn.multihead_attn.in_proj_bias <- src_index_289 shape=torch.Size([2304])\n",
      "copied by shape: dynamics.NO.blks.1.attn.multihead_attn.out_proj.weight <- src_index_289 shape=torch.Size([768, 768])\n",
      "copied by shape: dynamics.NO.blks.1.attn.multihead_attn.out_proj.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.1.normlayer2.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.1.normlayer2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.1.mlp.fc1.weight <- src_index_289 shape=torch.Size([3072, 768])\n",
      "copied by shape: dynamics.NO.blks.1.mlp.fc1.bias <- src_index_289 shape=torch.Size([3072])\n",
      "copied by shape: dynamics.NO.blks.1.mlp.fc2.weight <- src_index_289 shape=torch.Size([768, 3072])\n",
      "copied by shape: dynamics.NO.blks.1.mlp.fc2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.2.normlayer1.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.2.normlayer1.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.2.filter.w1 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.2.filter.b1 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.2.filter.w2 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.2.filter.b2 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.2.filter.bias.weight <- src_index_289 shape=torch.Size([768, 768, 1])\n",
      "copied by shape: dynamics.NO.blks.2.filter.bias.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.2.attn.multihead_attn.in_proj_weight <- src_index_289 shape=torch.Size([2304, 768])\n",
      "copied by shape: dynamics.NO.blks.2.attn.multihead_attn.in_proj_bias <- src_index_289 shape=torch.Size([2304])\n",
      "copied by shape: dynamics.NO.blks.2.attn.multihead_attn.out_proj.weight <- src_index_289 shape=torch.Size([768, 768])\n",
      "copied by shape: dynamics.NO.blks.2.attn.multihead_attn.out_proj.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.2.normlayer2.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.2.normlayer2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.2.mlp.fc1.weight <- src_index_289 shape=torch.Size([3072, 768])\n",
      "copied by shape: dynamics.NO.blks.2.mlp.fc1.bias <- src_index_289 shape=torch.Size([3072])\n",
      "copied by shape: dynamics.NO.blks.2.mlp.fc2.weight <- src_index_289 shape=torch.Size([768, 3072])\n",
      "copied by shape: dynamics.NO.blks.2.mlp.fc2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.3.normlayer1.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.3.normlayer1.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.3.filter.w1 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.3.filter.b1 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.3.filter.w2 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.3.filter.b2 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.3.filter.bias.weight <- src_index_289 shape=torch.Size([768, 768, 1])\n",
      "copied by shape: dynamics.NO.blks.3.filter.bias.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.3.attn.multihead_attn.in_proj_weight <- src_index_289 shape=torch.Size([2304, 768])\n",
      "copied by shape: dynamics.NO.blks.3.attn.multihead_attn.in_proj_bias <- src_index_289 shape=torch.Size([2304])\n",
      "copied by shape: dynamics.NO.blks.3.attn.multihead_attn.out_proj.weight <- src_index_289 shape=torch.Size([768, 768])\n",
      "copied by shape: dynamics.NO.blks.3.attn.multihead_attn.out_proj.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.3.normlayer2.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.3.normlayer2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.3.mlp.fc1.weight <- src_index_289 shape=torch.Size([3072, 768])\n",
      "copied by shape: dynamics.NO.blks.3.mlp.fc1.bias <- src_index_289 shape=torch.Size([3072])\n",
      "copied by shape: dynamics.NO.blks.3.mlp.fc2.weight <- src_index_289 shape=torch.Size([768, 3072])\n",
      "copied by shape: dynamics.NO.blks.3.mlp.fc2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.4.normlayer1.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.4.normlayer1.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.4.filter.w1 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.4.filter.b1 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.4.filter.w2 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.4.filter.b2 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.4.filter.bias.weight <- src_index_289 shape=torch.Size([768, 768, 1])\n",
      "copied by shape: dynamics.NO.blks.4.filter.bias.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.4.attn.multihead_attn.in_proj_weight <- src_index_289 shape=torch.Size([2304, 768])\n",
      "copied by shape: dynamics.NO.blks.4.attn.multihead_attn.in_proj_bias <- src_index_289 shape=torch.Size([2304])\n",
      "copied by shape: dynamics.NO.blks.4.attn.multihead_attn.out_proj.weight <- src_index_289 shape=torch.Size([768, 768])\n",
      "copied by shape: dynamics.NO.blks.4.attn.multihead_attn.out_proj.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.4.normlayer2.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.4.normlayer2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.4.mlp.fc1.weight <- src_index_289 shape=torch.Size([3072, 768])\n",
      "copied by shape: dynamics.NO.blks.4.mlp.fc1.bias <- src_index_289 shape=torch.Size([3072])\n",
      "copied by shape: dynamics.NO.blks.4.mlp.fc2.weight <- src_index_289 shape=torch.Size([768, 3072])\n",
      "copied by shape: dynamics.NO.blks.4.mlp.fc2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.5.normlayer1.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.5.normlayer1.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.5.filter.w1 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.5.filter.b1 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.5.filter.w2 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.5.filter.b2 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.5.filter.bias.weight <- src_index_289 shape=torch.Size([768, 768, 1])\n",
      "copied by shape: dynamics.NO.blks.5.filter.bias.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.5.attn.multihead_attn.in_proj_weight <- src_index_289 shape=torch.Size([2304, 768])\n",
      "copied by shape: dynamics.NO.blks.5.attn.multihead_attn.in_proj_bias <- src_index_289 shape=torch.Size([2304])\n",
      "copied by shape: dynamics.NO.blks.5.attn.multihead_attn.out_proj.weight <- src_index_289 shape=torch.Size([768, 768])\n",
      "copied by shape: dynamics.NO.blks.5.attn.multihead_attn.out_proj.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.5.normlayer2.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.5.normlayer2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.5.mlp.fc1.weight <- src_index_289 shape=torch.Size([3072, 768])\n",
      "copied by shape: dynamics.NO.blks.5.mlp.fc1.bias <- src_index_289 shape=torch.Size([3072])\n",
      "copied by shape: dynamics.NO.blks.5.mlp.fc2.weight <- src_index_289 shape=torch.Size([768, 3072])\n",
      "copied by shape: dynamics.NO.blks.5.mlp.fc2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.6.normlayer1.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.6.normlayer1.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.6.filter.w1 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.6.filter.b1 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.6.filter.w2 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.6.filter.b2 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.6.filter.bias.weight <- src_index_289 shape=torch.Size([768, 768, 1])\n",
      "copied by shape: dynamics.NO.blks.6.filter.bias.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.6.attn.multihead_attn.in_proj_weight <- src_index_289 shape=torch.Size([2304, 768])\n",
      "copied by shape: dynamics.NO.blks.6.attn.multihead_attn.in_proj_bias <- src_index_289 shape=torch.Size([2304])\n",
      "copied by shape: dynamics.NO.blks.6.attn.multihead_attn.out_proj.weight <- src_index_289 shape=torch.Size([768, 768])\n",
      "copied by shape: dynamics.NO.blks.6.attn.multihead_attn.out_proj.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.6.normlayer2.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.6.normlayer2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.6.mlp.fc1.weight <- src_index_289 shape=torch.Size([3072, 768])\n",
      "copied by shape: dynamics.NO.blks.6.mlp.fc1.bias <- src_index_289 shape=torch.Size([3072])\n",
      "copied by shape: dynamics.NO.blks.6.mlp.fc2.weight <- src_index_289 shape=torch.Size([768, 3072])\n",
      "copied by shape: dynamics.NO.blks.6.mlp.fc2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.7.normlayer1.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.7.normlayer1.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.7.filter.w1 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.7.filter.b1 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.7.filter.w2 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.7.filter.b2 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.7.filter.bias.weight <- src_index_289 shape=torch.Size([768, 768, 1])\n",
      "copied by shape: dynamics.NO.blks.7.filter.bias.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.7.attn.multihead_attn.in_proj_weight <- src_index_289 shape=torch.Size([2304, 768])\n",
      "copied by shape: dynamics.NO.blks.7.attn.multihead_attn.in_proj_bias <- src_index_289 shape=torch.Size([2304])\n",
      "copied by shape: dynamics.NO.blks.7.attn.multihead_attn.out_proj.weight <- src_index_289 shape=torch.Size([768, 768])\n",
      "copied by shape: dynamics.NO.blks.7.attn.multihead_attn.out_proj.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.7.normlayer2.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.7.normlayer2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.7.mlp.fc1.weight <- src_index_289 shape=torch.Size([3072, 768])\n",
      "copied by shape: dynamics.NO.blks.7.mlp.fc1.bias <- src_index_289 shape=torch.Size([3072])\n",
      "copied by shape: dynamics.NO.blks.7.mlp.fc2.weight <- src_index_289 shape=torch.Size([768, 3072])\n",
      "copied by shape: dynamics.NO.blks.7.mlp.fc2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.8.normlayer1.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.8.normlayer1.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.8.filter.w1 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.8.filter.b1 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.8.filter.w2 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.8.filter.b2 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.8.filter.bias.weight <- src_index_289 shape=torch.Size([768, 768, 1])\n",
      "copied by shape: dynamics.NO.blks.8.filter.bias.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.8.attn.multihead_attn.in_proj_weight <- src_index_289 shape=torch.Size([2304, 768])\n",
      "copied by shape: dynamics.NO.blks.8.attn.multihead_attn.in_proj_bias <- src_index_289 shape=torch.Size([2304])\n",
      "copied by shape: dynamics.NO.blks.8.attn.multihead_attn.out_proj.weight <- src_index_289 shape=torch.Size([768, 768])\n",
      "copied by shape: dynamics.NO.blks.8.attn.multihead_attn.out_proj.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.8.normlayer2.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.8.normlayer2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.8.mlp.fc1.weight <- src_index_289 shape=torch.Size([3072, 768])\n",
      "copied by shape: dynamics.NO.blks.8.mlp.fc1.bias <- src_index_289 shape=torch.Size([3072])\n",
      "copied by shape: dynamics.NO.blks.8.mlp.fc2.weight <- src_index_289 shape=torch.Size([768, 3072])\n",
      "copied by shape: dynamics.NO.blks.8.mlp.fc2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.9.normlayer1.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.9.normlayer1.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.9.filter.w1 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.9.filter.b1 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.9.filter.w2 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.9.filter.b2 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.9.filter.bias.weight <- src_index_289 shape=torch.Size([768, 768, 1])\n",
      "copied by shape: dynamics.NO.blks.9.filter.bias.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.9.attn.multihead_attn.in_proj_weight <- src_index_289 shape=torch.Size([2304, 768])\n",
      "copied by shape: dynamics.NO.blks.9.attn.multihead_attn.in_proj_bias <- src_index_289 shape=torch.Size([2304])\n",
      "copied by shape: dynamics.NO.blks.9.attn.multihead_attn.out_proj.weight <- src_index_289 shape=torch.Size([768, 768])\n",
      "copied by shape: dynamics.NO.blks.9.attn.multihead_attn.out_proj.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.9.normlayer2.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.9.normlayer2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.9.mlp.fc1.weight <- src_index_289 shape=torch.Size([3072, 768])\n",
      "copied by shape: dynamics.NO.blks.9.mlp.fc1.bias <- src_index_289 shape=torch.Size([3072])\n",
      "copied by shape: dynamics.NO.blks.9.mlp.fc2.weight <- src_index_289 shape=torch.Size([768, 3072])\n",
      "copied by shape: dynamics.NO.blks.9.mlp.fc2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.10.normlayer1.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.10.normlayer1.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.10.filter.w1 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.10.filter.b1 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.10.filter.w2 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.10.filter.b2 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.10.filter.bias.weight <- src_index_289 shape=torch.Size([768, 768, 1])\n",
      "copied by shape: dynamics.NO.blks.10.filter.bias.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.10.attn.multihead_attn.in_proj_weight <- src_index_289 shape=torch.Size([2304, 768])\n",
      "copied by shape: dynamics.NO.blks.10.attn.multihead_attn.in_proj_bias <- src_index_289 shape=torch.Size([2304])\n",
      "copied by shape: dynamics.NO.blks.10.attn.multihead_attn.out_proj.weight <- src_index_289 shape=torch.Size([768, 768])\n",
      "copied by shape: dynamics.NO.blks.10.attn.multihead_attn.out_proj.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.10.normlayer2.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.10.normlayer2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.10.mlp.fc1.weight <- src_index_289 shape=torch.Size([3072, 768])\n",
      "copied by shape: dynamics.NO.blks.10.mlp.fc1.bias <- src_index_289 shape=torch.Size([3072])\n",
      "copied by shape: dynamics.NO.blks.10.mlp.fc2.weight <- src_index_289 shape=torch.Size([768, 3072])\n",
      "copied by shape: dynamics.NO.blks.10.mlp.fc2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.11.normlayer1.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.11.normlayer1.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.11.filter.w1 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.11.filter.b1 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.11.filter.w2 <- src_index_289 shape=torch.Size([2, 2, 384, 384])\n",
      "copied by shape: dynamics.NO.blks.11.filter.b2 <- src_index_289 shape=torch.Size([2, 2, 384])\n",
      "copied by shape: dynamics.NO.blks.11.filter.bias.weight <- src_index_289 shape=torch.Size([768, 768, 1])\n",
      "copied by shape: dynamics.NO.blks.11.filter.bias.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.11.attn.multihead_attn.in_proj_weight <- src_index_289 shape=torch.Size([2304, 768])\n",
      "copied by shape: dynamics.NO.blks.11.attn.multihead_attn.in_proj_bias <- src_index_289 shape=torch.Size([2304])\n",
      "copied by shape: dynamics.NO.blks.11.attn.multihead_attn.out_proj.weight <- src_index_289 shape=torch.Size([768, 768])\n",
      "copied by shape: dynamics.NO.blks.11.attn.multihead_attn.out_proj.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.11.normlayer2.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.11.normlayer2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.blks.11.mlp.fc1.weight <- src_index_289 shape=torch.Size([3072, 768])\n",
      "copied by shape: dynamics.NO.blks.11.mlp.fc1.bias <- src_index_289 shape=torch.Size([3072])\n",
      "copied by shape: dynamics.NO.blks.11.mlp.fc2.weight <- src_index_289 shape=torch.Size([768, 3072])\n",
      "copied by shape: dynamics.NO.blks.11.mlp.fc2.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.norm.weight <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.norm.bias <- src_index_289 shape=torch.Size([768])\n",
      "copied by shape: dynamics.NO.lproj.transposeconv1.weight <- src_index_289 shape=torch.Size([768, 80, 2, 2])\n",
      "copied by shape: dynamics.NO.lproj.transposeconv1.bias <- src_index_289 shape=torch.Size([80])\n",
      "copied by shape: dynamics.NO.lproj.transposeconv2.weight <- src_index_289 shape=torch.Size([80, 20, 2, 2])\n",
      "copied by shape: dynamics.NO.lproj.transposeconv2.bias <- src_index_289 shape=torch.Size([20])\n",
      "copied by shape: dynamics.NO.lproj.transposeconv3.weight <- src_index_289 shape=torch.Size([20, 5, 4, 4])\n",
      "copied by shape: dynamics.NO.lproj.transposeconv3.bias <- src_index_288 shape=torch.Size([5])\n",
      "copied by shape: dynamics.up.weight <- src_index_289 shape=torch.Size([5, 5, 3, 3])\n",
      "copied by shape: dynamics.up.bias <- src_index_288 shape=torch.Size([5])\n",
      "copied by shape: dynamics.down.weight <- src_index_289 shape=torch.Size([5, 5, 3, 3])\n",
      "copied by shape: dynamics.down.bias <- src_index_288 shape=torch.Size([5])\n",
      "copied by shape: dynamics.conv1x1.weight <- src_index_289 shape=torch.Size([5, 5, 1, 1])\n",
      "copied by shape: dynamics.conv1x1.bias <- src_index_288 shape=torch.Size([5])\n",
      "copied by shape: mapsback.readout.bias <- src_index_288 shape=torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "# build lists of remaining src/tgt tensors\n",
    "remaining_src = [p for n, p in src_params.items() if n not in set(copied)]\n",
    "remaining_tgt = [(n, p) for n, p in new_model.named_parameters() if n not in set(copied)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tgt_name, tgt in remaining_tgt:\n",
    "        for i, src in enumerate(remaining_src):\n",
    "            if tuple(src.shape) == tuple(tgt.shape):\n",
    "                tgt.copy_(src.to(tgt.device).to(tgt.dtype))\n",
    "                print(f\"copied by shape: {tgt_name} <- src_index_{i} shape={src.shape}\")\n",
    "                remaining_src.pop(i)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a22deb",
   "metadata": {},
   "source": [
    "- If `model` is a traced/inference TorchScript that explicitly uses `torch.no_grad()` or detaches its outputs, gradients cannot flow even if you copy weights; you'll need the original model class + state_dict to get a differentiable forward.\n",
    "- Name mismatches are common when model code changed or when using wrappers (DataParallel, prefix differences). Manual mapping may be required.\n",
    "- Always check shapes before copying; copying mismatched shapes will raise errors.\n",
    "- After copying, set `new_model.eval()` or `.train()` as needed, and move it to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4911481b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_model forward OK, out type: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "new_model.eval()\n",
    "# create a small dummy input matching new_model expectation and run a forward\n",
    "x_test = torch.randn(1, 2, 5, 672, 1440, device=device)  # replace with correct dims\n",
    "try:\n",
    "    out = new_model(x_test)\n",
    "    print(\"new_model forward OK, out type:\", type(out))\n",
    "except Exception as e:\n",
    "    print(\"forward failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df41862",
   "metadata": {},
   "source": [
    "- ScriptModule often supports `state_dict()` and `named_parameters()`; prefer `state_dict()` when available.\n",
    "- Always use `torch.no_grad()` when copying `.data` to avoid creating graph connections.\n",
    "- Ensure dtype/device match: use `.to(tgt.device).to(tgt.dtype)` when copying.\n",
    "- If names differ due to wrappers or refactoring, manual name mapping might be needed.\n",
    "- If the ScriptModule was traced/inference-only, weights still copy fine; the problem you had earlier came from trying `torch.load` with the wrong flags — using `torch.jit.load` (what you already did) is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aa7222",
   "metadata": {},
   "source": [
    "Empty gpu's memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52e7c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "model.to('cpu')\n",
    "del x_test\n",
    "del out\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "try:\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dfe1b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.requires_grad: True\n",
      "forward ok, out type: <class 'torch.Tensor'>\n",
      "out_t.shape: torch.Size([1, 5, 672, 1440])\n",
      "out_t.requires_grad: True\n",
      "out_t.grad_fn: <SelectBackward0 object at 0x71afede19d20>\n",
      "loss.requires_grad: True\n",
      "x.grad norm: 98.10212707519531\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test that new_model allows gradients w.r.t. input (freeze weights, track input)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "new_model.to(device)\n",
    "# Freeze model weights\n",
    "for p in new_model.parameters():\n",
    "    p.requires_grad = False\n",
    "new_model.eval()\n",
    "\n",
    "# Create input with requires_grad=True. Adjust shape if your model expects different dims.\n",
    "x = torch.randn(1, 2, 5, 672, 1440, device=device, requires_grad=True)\n",
    "print('x.requires_grad:', x.requires_grad)\n",
    "\n",
    "# Forward pass and inspect output's grad properties\n",
    "try:\n",
    "    out = new_model(x)\n",
    "    print('forward ok, out type:', type(out))\n",
    "except Exception as e:\n",
    "    print('forward failed:', e)\n",
    "    out = None\n",
    "\n",
    "def first_tensor(o):\n",
    "    if torch.is_tensor(o):\n",
    "        return o\n",
    "    if isinstance(o, (list, tuple)):\n",
    "        for v in o:\n",
    "            t = first_tensor(v)\n",
    "            if t is not None:\n",
    "                return t\n",
    "    if isinstance(o, dict):\n",
    "        for v in o.values():\n",
    "            t = first_tensor(v)\n",
    "            if t is not None:\n",
    "                return t\n",
    "    return None\n",
    "\n",
    "if out is None:\n",
    "    print('No output to test')\n",
    "else:\n",
    "    out_t = first_tensor(out)\n",
    "    if out_t is None:\n",
    "        print('No tensor found inside model output')\n",
    "    else:\n",
    "        print('out_t.shape:', getattr(out_t, 'shape', None))\n",
    "        print('out_t.requires_grad:', out_t.requires_grad)\n",
    "        print('out_t.grad_fn:', out_t.grad_fn)\n",
    "        if not out_t.requires_grad:\n",
    "            print('Output does not require grad — likely the forward detached tensors or used no_grad.')\n",
    "        else:\n",
    "            # backprop and check x.grad\n",
    "            loss = out_t.sum()\n",
    "            print('loss.requires_grad:', loss.requires_grad)\n",
    "            loss.backward()\n",
    "            if x.grad is None:\n",
    "                print('x.grad is None — gradient did not flow into input')\n",
    "            else:\n",
    "                print('x.grad norm:', x.grad.norm().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cbf5968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reusing existing `x` from earlier cells\n",
      "start x norm: 3111.773682\n",
      "step 00 loss=3.222114e+04 x.grad_norm=9.810213e+01 x.norm=3111.773682\n",
      "step 01 loss=3.212335e+04 x.grad_norm=9.829488e+01 x.norm=3111.771973\n",
      "step 02 loss=3.196002e+04 x.grad_norm=9.815225e+01 x.norm=3111.770020\n",
      "step 03 loss=3.174892e+04 x.grad_norm=9.814280e+01 x.norm=3111.768311\n",
      "step 04 loss=3.150391e+04 x.grad_norm=9.867900e+01 x.norm=3111.768555\n",
      "step 05 loss=3.123515e+04 x.grad_norm=9.872153e+01 x.norm=3111.771240\n",
      "step 06 loss=3.094846e+04 x.grad_norm=9.851047e+01 x.norm=3111.777100\n",
      "step 07 loss=3.065337e+04 x.grad_norm=9.836958e+01 x.norm=3111.785400\n",
      "step 08 loss=3.035120e+04 x.grad_norm=9.775131e+01 x.norm=3111.797607\n",
      "step 09 loss=3.004380e+04 x.grad_norm=9.781171e+01 x.norm=3111.813232\n",
      "step 10 loss=2.973248e+04 x.grad_norm=9.803963e+01 x.norm=3111.832275\n",
      "step 11 loss=2.941838e+04 x.grad_norm=9.788206e+01 x.norm=3111.854980\n",
      "step 12 loss=2.910250e+04 x.grad_norm=9.806225e+01 x.norm=3111.881348\n",
      "step 13 loss=2.878544e+04 x.grad_norm=9.793162e+01 x.norm=3111.911377\n",
      "step 14 loss=2.846633e+04 x.grad_norm=9.841270e+01 x.norm=3111.944580\n",
      "step 15 loss=2.814795e+04 x.grad_norm=9.816104e+01 x.norm=3111.981445\n",
      "step 16 loss=2.782775e+04 x.grad_norm=9.805432e+01 x.norm=3112.021973\n",
      "step 17 loss=2.750909e+04 x.grad_norm=9.799554e+01 x.norm=3112.066162\n",
      "step 18 loss=2.718822e+04 x.grad_norm=9.845161e+01 x.norm=3112.113770\n",
      "step 19 loss=2.686756e+04 x.grad_norm=9.852685e+01 x.norm=3112.165283\n",
      "step 20 loss=2.654521e+04 x.grad_norm=9.841286e+01 x.norm=3112.220459\n",
      "step 21 loss=2.622411e+04 x.grad_norm=9.796721e+01 x.norm=3112.278809\n",
      "step 22 loss=2.590407e+04 x.grad_norm=9.812885e+01 x.norm=3112.341309\n",
      "step 23 loss=2.558284e+04 x.grad_norm=9.863653e+01 x.norm=3112.406982\n",
      "step 24 loss=2.526018e+04 x.grad_norm=9.859847e+01 x.norm=3112.476074\n",
      "step 25 loss=2.493595e+04 x.grad_norm=9.912019e+01 x.norm=3112.549072\n",
      "step 26 loss=2.461068e+04 x.grad_norm=9.923759e+01 x.norm=3112.625488\n",
      "step 27 loss=2.428340e+04 x.grad_norm=9.970214e+01 x.norm=3112.705566\n",
      "step 28 loss=2.395466e+04 x.grad_norm=9.974930e+01 x.norm=3112.789307\n",
      "step 29 loss=2.362436e+04 x.grad_norm=9.989250e+01 x.norm=3112.876953\n",
      "step 30 loss=2.329454e+04 x.grad_norm=9.954250e+01 x.norm=3112.968262\n",
      "step 31 loss=2.296399e+04 x.grad_norm=9.984265e+01 x.norm=3113.063232\n",
      "step 32 loss=2.263304e+04 x.grad_norm=9.993027e+01 x.norm=3113.161377\n",
      "step 33 loss=2.230071e+04 x.grad_norm=1.002599e+02 x.norm=3113.263184\n",
      "step 34 loss=2.196783e+04 x.grad_norm=1.000089e+02 x.norm=3113.368896\n",
      "step 35 loss=2.163462e+04 x.grad_norm=1.003579e+02 x.norm=3113.478027\n",
      "step 36 loss=2.129889e+04 x.grad_norm=1.007629e+02 x.norm=3113.590576\n",
      "step 37 loss=2.096329e+04 x.grad_norm=1.005599e+02 x.norm=3113.707031\n",
      "step 38 loss=2.062632e+04 x.grad_norm=1.011012e+02 x.norm=3113.827393\n",
      "step 39 loss=2.028670e+04 x.grad_norm=1.017449e+02 x.norm=3113.951416\n",
      "step 40 loss=1.994383e+04 x.grad_norm=1.027873e+02 x.norm=3114.079346\n",
      "step 41 loss=1.959383e+04 x.grad_norm=1.038478e+02 x.norm=3114.211426\n",
      "step 42 loss=1.924124e+04 x.grad_norm=1.039219e+02 x.norm=3114.348145\n",
      "step 43 loss=1.888590e+04 x.grad_norm=1.038631e+02 x.norm=3114.489014\n",
      "step 44 loss=1.852948e+04 x.grad_norm=1.038003e+02 x.norm=3114.634033\n",
      "step 45 loss=1.817091e+04 x.grad_norm=1.044614e+02 x.norm=3114.782959\n",
      "step 46 loss=1.781083e+04 x.grad_norm=1.043434e+02 x.norm=3114.936035\n",
      "step 47 loss=1.744866e+04 x.grad_norm=1.052002e+02 x.norm=3115.093262\n",
      "step 48 loss=1.708339e+04 x.grad_norm=1.054092e+02 x.norm=3115.254639\n",
      "step 49 loss=1.671535e+04 x.grad_norm=1.060383e+02 x.norm=3115.420654\n",
      "step 50 loss=1.634375e+04 x.grad_norm=1.059560e+02 x.norm=3115.591064\n",
      "step 51 loss=1.597112e+04 x.grad_norm=1.066285e+02 x.norm=3115.765137\n",
      "step 52 loss=1.559426e+04 x.grad_norm=1.072818e+02 x.norm=3115.944092\n",
      "step 53 loss=1.521416e+04 x.grad_norm=1.075093e+02 x.norm=3116.127686\n",
      "step 54 loss=1.483084e+04 x.grad_norm=1.082066e+02 x.norm=3116.315674\n",
      "step 55 loss=1.444494e+04 x.grad_norm=1.079728e+02 x.norm=3116.509033\n",
      "step 56 loss=1.405772e+04 x.grad_norm=1.086598e+02 x.norm=3116.706055\n",
      "step 57 loss=1.366685e+04 x.grad_norm=1.089005e+02 x.norm=3116.907715\n",
      "step 58 loss=1.327479e+04 x.grad_norm=1.086170e+02 x.norm=3117.114014\n",
      "step 59 loss=1.288315e+04 x.grad_norm=1.093549e+02 x.norm=3117.324463\n",
      "step 60 loss=1.248633e+04 x.grad_norm=1.099294e+02 x.norm=3117.539307\n",
      "step 61 loss=1.208669e+04 x.grad_norm=1.107862e+02 x.norm=3117.758789\n",
      "step 62 loss=1.168084e+04 x.grad_norm=1.116654e+02 x.norm=3117.983887\n",
      "step 63 loss=1.127093e+04 x.grad_norm=1.116004e+02 x.norm=3118.214111\n",
      "step 64 loss=1.086028e+04 x.grad_norm=1.115278e+02 x.norm=3118.449219\n",
      "step 65 loss=1.044801e+04 x.grad_norm=1.122600e+02 x.norm=3118.689453\n",
      "step 66 loss=1.002897e+04 x.grad_norm=1.131324e+02 x.norm=3118.934326\n",
      "step 67 loss=9.607819e+03 x.grad_norm=1.132281e+02 x.norm=3119.185059\n",
      "step 68 loss=9.184091e+03 x.grad_norm=1.133626e+02 x.norm=3119.440430\n",
      "step 69 loss=8.758881e+03 x.grad_norm=1.138731e+02 x.norm=3119.700684\n",
      "step 70 loss=8.329110e+03 x.grad_norm=1.135713e+02 x.norm=3119.966064\n",
      "step 71 loss=7.901004e+03 x.grad_norm=1.139828e+02 x.norm=3120.235840\n",
      "step 72 loss=7.469051e+03 x.grad_norm=1.142184e+02 x.norm=3120.510254\n",
      "step 73 loss=7.034705e+03 x.grad_norm=1.153249e+02 x.norm=3120.789551\n",
      "step 74 loss=6.595088e+03 x.grad_norm=1.159480e+02 x.norm=3121.073975\n",
      "step 75 loss=6.152121e+03 x.grad_norm=1.164838e+02 x.norm=3121.364014\n",
      "step 76 loss=5.704377e+03 x.grad_norm=1.164067e+02 x.norm=3121.659424\n",
      "step 77 loss=5.253065e+03 x.grad_norm=1.173088e+02 x.norm=3121.960449\n",
      "step 78 loss=4.799392e+03 x.grad_norm=1.172635e+02 x.norm=3122.266846\n",
      "step 79 loss=4.343759e+03 x.grad_norm=1.181050e+02 x.norm=3122.578857\n",
      "step 80 loss=3.882199e+03 x.grad_norm=1.187790e+02 x.norm=3122.895996\n",
      "step 81 loss=3.416043e+03 x.grad_norm=1.189248e+02 x.norm=3123.218750\n",
      "step 82 loss=2.948841e+03 x.grad_norm=1.193852e+02 x.norm=3123.547607\n",
      "step 83 loss=2.478490e+03 x.grad_norm=1.189011e+02 x.norm=3123.881592\n",
      "step 84 loss=2.009075e+03 x.grad_norm=1.197549e+02 x.norm=3124.220459\n",
      "step 85 loss=1.534385e+03 x.grad_norm=1.195477e+02 x.norm=3124.564209\n",
      "step 86 loss=1.058867e+03 x.grad_norm=1.198724e+02 x.norm=3124.913086\n",
      "step 87 loss=5.834312e+02 x.grad_norm=1.207204e+02 x.norm=3125.266602\n",
      "step 88 loss=1.021167e+02 x.grad_norm=1.209553e+02 x.norm=3125.626221\n",
      "step 89 loss=-3.841160e+02 x.grad_norm=1.219639e+02 x.norm=3125.990967\n",
      "step 90 loss=-8.744702e+02 x.grad_norm=1.218437e+02 x.norm=3126.361816\n",
      "step 91 loss=-1.366035e+03 x.grad_norm=1.224138e+02 x.norm=3126.738281\n",
      "step 92 loss=-1.859728e+03 x.grad_norm=1.229187e+02 x.norm=3127.120117\n",
      "step 93 loss=-2.358284e+03 x.grad_norm=1.228559e+02 x.norm=3127.508301\n",
      "step 94 loss=-2.859640e+03 x.grad_norm=1.235567e+02 x.norm=3127.901855\n",
      "step 95 loss=-3.365814e+03 x.grad_norm=1.243471e+02 x.norm=3128.301514\n",
      "step 96 loss=-3.877337e+03 x.grad_norm=1.244694e+02 x.norm=3128.707520\n",
      "step 97 loss=-4.392050e+03 x.grad_norm=1.260856e+02 x.norm=3129.119141\n",
      "step 98 loss=-4.915285e+03 x.grad_norm=1.265435e+02 x.norm=3129.537598\n",
      "step 99 loss=-5.440488e+03 x.grad_norm=1.266072e+02 x.norm=3129.962891\n",
      "end x norm: 3130.394531 (changed by 18.620850)\n",
      "final x_param.requires_grad: True\n",
      "out_t.requires_grad: True out_t.grad_fn: <SelectBackward0 object at 0x71afedfb2650>\n"
     ]
    }
   ],
   "source": [
    "# Simple gradient descent on input `x` to verify gradients flow into the input\n",
    "# If `x` exists from earlier cells we reuse it, otherwise create a random init.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "new_model.to(device)\n",
    "for p in new_model.parameters():\n",
    "    p.requires_grad = False\n",
    "new_model.eval()\n",
    "\n",
    "try:\n",
    "    x_init = x.detach().clone().to(device)\n",
    "    print('reusing existing `x` from earlier cells')\n",
    "except NameError:\n",
    "    x_init = torch.randn(1, 2, 5, 672, 1440, device=device)\n",
    "    print('created new random `x_init`')\n",
    "\n",
    "# Wrap the input as a Parameter so it can be optimized by an optimizer\n",
    "x_param = torch.nn.Parameter(x_init, requires_grad=True)\n",
    "opt = torch.optim.SGD([x_param], lr=1e-2, momentum=0.7)\n",
    "\n",
    "start_norm = x_param.data.norm().item()\n",
    "print(f'start x norm: {start_norm:.6f}')\n",
    "\n",
    "# small training loop\n",
    "steps = 100\n",
    "for i in range(steps):\n",
    "    opt.zero_grad()\n",
    "    out = new_model(x_param)\n",
    "\n",
    "    # helper to find first tensor in output\n",
    "    def first_tensor(o):\n",
    "        if torch.is_tensor(o):\n",
    "            return o\n",
    "        if isinstance(o, (list, tuple)):\n",
    "            for v in o:\n",
    "                t = first_tensor(v)\n",
    "                if t is not None:\n",
    "                    return t\n",
    "        if isinstance(o, dict):\n",
    "            for v in o.values():\n",
    "                t = first_tensor(v)\n",
    "                if t is not None:\n",
    "                    return t\n",
    "        return None\n",
    "\n",
    "    out_t = first_tensor(out)\n",
    "    if out_t is None:\n",
    "        print('Model returned no tensor; cannot compute loss. Stopping.')\n",
    "        break\n",
    "\n",
    "    loss = out_t.sum()  # simple scalar to exercise gradients\n",
    "    loss.backward()\n",
    "\n",
    "    grad_norm = x_param.grad.norm().item() if x_param.grad is not None else float('nan')\n",
    "    print(f'step {i:02d} loss={loss.item():.6e} x.grad_norm={grad_norm:.6e} x.norm={x_param.data.norm().item():.6f}')\n",
    "\n",
    "    opt.step()\n",
    "\n",
    "end_norm = x_param.data.norm().item()\n",
    "print(f'end x norm: {end_norm:.6f} (changed by {end_norm - start_norm:.6f})')\n",
    "print('final x_param.requires_grad:', x_param.requires_grad)\n",
    "print('out_t.requires_grad:', getattr(out_t, 'requires_grad', None), 'out_t.grad_fn:', getattr(out_t, 'grad_fn', None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3344bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
