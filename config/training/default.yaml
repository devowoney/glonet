# ---------------------------- Default configuration for training
# config/
#   |- training/
#        |- default.yaml
# -----------------------------


datamodule:
  forecast_horizon: 3
  batch_size: 1
  num_workers: 0

callbacks:
  monitor: "train_loss"
  dirpath: ${hydra:run.dir}/checkpoints
  filename: "best-model-{epoch:02d}-{train_loss:.2f}"
  save_top_k: 3
  mode: "min"

tensorboard:  
  save_dir: ${hydra:run.dir}
  name: input_${state_number}_${training.datamodule.forecast_horizon}d_window
  version: lr1e-4wd1e-2

trainer:
  epochs: 1000
  accelerator: "gpu"
  devices: 1
  log_every_n_steps: 1
  grad_clip_norm: 1.0
  precision: 32

#------- defined in Glonet class --------

optimizer:
  _target_: torch.optim.Adam
  lr: 1e-4
  weight_decay: 1e-2
  betas: [0.9, 0.999]

scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  T_max: ${training.trainer.epochs}
  eta_min: 1e-6

# loss:
#   _target_: torch.nn.MSELoss
