# Fast training configuration for testing
epochs: 10
batch_size: 2
learning_rate: 0.01
weight_decay: 0

optimizer:
  _target_: torch.optim.SGD
  lr: ${training.learning_rate}
  momentum: 0.9

scheduler:
  _target_: torch.optim.lr_scheduler.StepLR
  step_size: 5
  gamma: 0.5

loss:
  _target_: torch.nn.MSELoss

grad_clip_norm: 0.5
use_amp: false
